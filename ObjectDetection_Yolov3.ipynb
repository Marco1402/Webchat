{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Roboflow-Yolov3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marco1402/Webchat/blob/master/ObjectDetection_Yolov3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFhMDyD-vXLs",
        "colab_type": "text"
      },
      "source": [
        "NOTE: For the most up to date version of this notebook, please be sure to copy from this link:\n",
        " \n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ByRi9d6_Yzu0nrEKArmLMLuMaZjYfygO#scrollTo=WgHANbxqWJPa)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgHANbxqWJPa",
        "colab_type": "text"
      },
      "source": [
        "## **Training YOLOv3 object detection on a custom dataset**\n",
        "\n",
        "ðŸ’¡ Recommendation: [Open this blog post](https://blog.roboflow.ai/training-a-yolov3-object-detection-model-with-a-custom-dataset/) to continue.\n",
        "\n",
        "### **Overview**\n",
        "\n",
        "This notebook walks through how to train a YOLOv3 object detection model on your own dataset using Roboflow and Colab.\n",
        "\n",
        "In this specific example, we'll training an object detection model to recognize chess pieces in images. **To adapt this example to your own dataset, you only need to change one line of code in this notebook.**\n",
        "\n",
        "![Chess Example](https://i.imgur.com/nkjobw1.png)\n",
        "\n",
        "### **Our Data**\n",
        "\n",
        "Our dataset of 289 chess images (and 2894 annotations!) is hosted publicly on Roboflow [here](https://public.roboflow.ai/object-detection/chess-full).\n",
        "\n",
        "### **Our Model**\n",
        "\n",
        "We'll be training a YOLOv3 (You Only Look Once) model. This specific model is a one-shot learner, meaning each image only passes through the network once to make a prediction, which allows the architecture to be very performant, viewing up to 60 frames per second in predicting against video feeds.\n",
        "\n",
        "The GitHub repo containing the majority of the code we'll use is available [here](https://github.com/roboflow-ai/keras-yolo3.git).\n",
        "\n",
        "### **Training**\n",
        "\n",
        "Google Colab provides free GPU resources. Click \"Runtime\" â†’ \"Change runtime type\" â†’ Hardware Accelerator dropdown to \"GPU.\"\n",
        "\n",
        "Colab does have memory limitations, and notebooks must be open in your browser to run. Sessions automatically clear themselves after 24 hours.\n",
        "\n",
        "### **Inference**\n",
        "\n",
        "We'll leverage the `python_video.py` script to produce predictions. Arguments are specified below.\n",
        "\n",
        "It's recommended that you expand the left-hand panel to view this notebook's Table of contents, Code Snippets, and Files. \n",
        "\n",
        "![Expand Colab](https://i.imgur.com/r8kWzIv.png \"Click here\")\n",
        "\n",
        "Then, click \"Files.\" You'll see files appear here as we work through the notebook.\n",
        "\n",
        "\n",
        "### **About**\n",
        "\n",
        "[Roboflow](https://roboflow.ai) makes managing, preprocessing, augmenting, and versioning datasets for computer vision seamless.\n",
        "\n",
        "Developers reduce 50% of their boilerplate code when using Roboflow's workflow, save training time, and increase model reproducibility.\n",
        "\n",
        "#### ![Roboflow Workmark](https://i.imgur.com/WHFqYSJ.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHNPC6kwbKAL",
        "colab_type": "text"
      },
      "source": [
        "## Setup our environment\n",
        "\n",
        "First, we'll install the version of Keras our YOLOv3 implementation calls for and verify it installs corrects. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pyrwfpiiEkH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59d901f9-0c5b-4607-87d6-b5668eb50662"
      },
      "source": [
        "# Get our kernel running\n",
        "print(\"Hello, Roboflow\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello, Roboflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRIj10jNhqH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "outputId": "035041d1-46e9-4fb2-ae25-3d16742b2706"
      },
      "source": [
        "# Our YOLOv3 implementation calls for this Keras version\n",
        "!pip install keras==2.2.4\n",
        "!pip install tensorflow==1.14.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.5)\n",
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.30.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (49.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r788kvmKuD5O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ce32cb1a-531c-42e8-ed41-9d180650399e"
      },
      "source": [
        "# use TF 1.x\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMI-zNrrhmuG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "fc078a56-b356-494b-fcf9-1b6c6c3538d2"
      },
      "source": [
        "# Verify our version is correct\n",
        "!python -c 'import keras; print(keras.__version__)'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lweWDcTyVeLs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "9ed1fc7d-4084-4863-8077-412166945e54"
      },
      "source": [
        "# Next, we'll grab all the code from our repository of interest \n",
        "!git clone https://github.com/roboflow-ai/keras-yolo3"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-yolo3'...\n",
            "remote: Enumerating objects: 169, done.\u001b[K\n",
            "remote: Total 169 (delta 0), reused 0 (delta 0), pack-reused 169\u001b[K\n",
            "Receiving objects: 100% (169/169), 172.74 KiB | 6.91 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyPfLjFBbOAw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fa588f94-ff29-4a0d-f396-89acfc8e598c"
      },
      "source": [
        "# here's what we cloned (also, see \"Files\" in the left-hand Colab pane)\n",
        "%ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mkeras-yolo3\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adwdKfxBVlom",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "583b3bf6-7b3d-4712-9bd4-c92adf334e3f"
      },
      "source": [
        "# change directory to the repo we cloned\n",
        "%cd keras-yolo3/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-yolo3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6DNWhOEbGB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "1793b092-a229-40ac-88b1-d1acb8bacc20"
      },
      "source": [
        "# show the contents of our repo\n",
        "%ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "coco_annotation.py  LICENSE              Tutorial.ipynb     yolov3-tiny.cfg\n",
            "convert.py          \u001b[0m\u001b[01;34mmodel_data\u001b[0m/          voc_annotation.py  yolo_video.py\n",
            "darknet53.cfg       README.md            \u001b[01;34myolo3\u001b[0m/\n",
            "\u001b[01;34mfont\u001b[0m/               train_bottleneck.py  yolo.py\n",
            "kmeans.py           train.py             yolov3.cfg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I--RqDmpwqmv",
        "colab_type": "text"
      },
      "source": [
        "## Get our training data from Roboflow\n",
        "\n",
        "Next, we need to add our data from Roboflow into our environment.\n",
        "\n",
        "Our dataset, with annotations, is [here](https://public.roboflow.ai/object-detection/chess-full).\n",
        "\n",
        "Here's how to bring those images from Roboflow to Colab:\n",
        "\n",
        "1. Visit this [link](https://public.roboflow.ai/object-detection/chess-full).\n",
        "2. Click the \"416x416auto-orient\" under Downloads.\n",
        "3. On the dataset detail page, select \"Download\" in the upper right-hand corner.\n",
        "4. If you are not signed in, you will be prompted to create a free account (sign in with GitHub or email), and redirected to the dataset page to Download.\n",
        "5. On the download popup, select the YOLOv3 Keras option **and** the \"Show download `code`\". \n",
        "6. Copy the code snippet Roboflow generates for you, and paste it in the next cell.\n",
        "\n",
        "This is the download menu you want (from step 5):\n",
        "#### ![Download Menu](https://i.imgur.com/KW2PyQO.png)\n",
        "\n",
        "The top code snippet is the one you want to copy (from step 6) and paste in the next notebook cell:\n",
        "### ![Code Snippet](https://i.imgur.com/qzJckWR.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AmSSTFFWud7",
        "colab_type": "text"
      },
      "source": [
        "**This cell below is only one you need to change to have YOLOv3 train on your own Roboflow dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nclkjonbT25",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3e6c7acc-5e75-4bf1-d2a8-1236cecd4e44"
      },
      "source": [
        "# Paste Roboflow code from snippet here from above to here! eg !curl -L https://app.roboflow.ai/ds/eOSXbt7KWu?key=YOURKEY | jar -x\n",
        "!curl -L \"https://public.roboflow.ai/ds/73TGKDTBa1?key=7U6JFonnkj\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   892  100   892    0     0   1256      0 --:--:-- --:--:-- --:--:--  1254\n",
            "100 7041k  100 7041k    0     0  8245k      0 --:--:-- --:--:-- --:--:-- 8245k\n",
            "Archive:  roboflow.zip\n",
            " extracting: test/ba6289667457a113c1a753a87c041c51_jpg.rf.31874cd941dfda8ac86b77fdc97f4931.jpg  \n",
            " extracting: test/e4583d082076b2b549b3736ad1b193c9_jpg.rf.55af0c9be903e4dda4a002af87bdeaac.jpg  \n",
            " extracting: test/fdcd6ada676799da8a870f58fdf548db_jpg.rf.bdda51ee840f036af9280598f08b1879.jpg  \n",
            " extracting: test/7a34d8620235048917b28bcfd3b5572b_jpg.rf.182f59c512dcb99ed53da97dfe2d3d85.jpg  \n",
            " extracting: test/e0d38d159ad3a801d0304d7e275812cc_jpg.rf.0cd06a940ccc9894109d83792535e3eb.jpg  \n",
            " extracting: test/c5a012dfa72816098d23fc8baee67834_jpg.rf.8b0e56e40c7c2429ce0e56797eb55c88.jpg  \n",
            " extracting: test/2f6fb003bb89cd401322a535acb42f65_jpg.rf.49b342a7b1f6de3f0e328beaf094a945.jpg  \n",
            " extracting: test/4e3117459d759798537eb52cf5bf534d_jpg.rf.437c663d542c17860c1e82c1fca878e6.jpg  \n",
            " extracting: test/1c0060ef868bdc326ce5e6389cb6732f_jpg.rf.a07af6147d4a79376c182d2d95c639ec.jpg  \n",
            " extracting: test/a3863d0be6002c21b20ac88817b2c56f_jpg.rf.ba355f57305a2236db1a9cfb0ac79989.jpg  \n",
            " extracting: test/749e9074a77f8d34d86e2218f26cdab4_jpg.rf.ac8241b790c765e76eb65db0e3239302.jpg  \n",
            " extracting: test/8ff752f9ed443e6e49d495abfceb2032_jpg.rf.4d299f90a6d716ab9d8a7d1741c26b62.jpg  \n",
            " extracting: test/5a35ba2ec3e0d0b2b12b1758a8ac29aa_jpg.rf.280f9940defacbb5d840aef65a9257e5.jpg  \n",
            " extracting: test/cf4769d0586df6b3fb0dc618d9f8abe6_jpg.rf.699ec58d7d2447b4d73b748c39525b2d.jpg  \n",
            " extracting: test/73a38a5c8f8f1b09f093f304660d5326_jpg.rf.b23ca34654408e01ab45b9c780032dfd.jpg  \n",
            " extracting: test/c4943d83c06a12ad5e0399d19514a4ca_jpg.rf.8197feccc16483d753bdd671cf29a174.jpg  \n",
            " extracting: test/cfc306bf86176b92ffc1afbb98d7896f_jpg.rf.2de0d2da0025b5993598f47fb1d51d10.jpg  \n",
            " extracting: test/8b457d1c86ad0c8e734b78de2f974fe6_jpg.rf.c2b8260a74f1b24b36c5e5e1cae8ef1d.jpg  \n",
            " extracting: test/0b47311f426ff926578c9d738d683e76_jpg.rf.58093f799a6f56c30830617ca44745ca.jpg  \n",
            " extracting: test/d7887071e972604ddf5940d8eb2702e7_jpg.rf.78288a14dc86417b6d3e798fa7fb5cf3.jpg  \n",
            " extracting: test/b4ff4132c8c85da97d8bf9a2a4ed3e3d_jpg.rf.445b4d70e01a3d742ecf0b7756e636da.jpg  \n",
            " extracting: test/685b860d412b91f5d4f7f9e643b84452_jpg.rf.4271132b4ce08c4ec0987ab2490e7edc.jpg  \n",
            " extracting: test/e4147f3d8819fc5d67a9f72596bd9e47_jpg.rf.61c071896199b2723723ba615ce57cb2.jpg  \n",
            " extracting: test/33afc6085c4d5a8f2421c1adc5a1edbf_jpg.rf.642c5b5370e5900cae860045ade36211.jpg  \n",
            " extracting: test/f1a24b6bb778ee11ba33687415aa84f2_jpg.rf.c3f21b35159c24fd853cb1da56f80d6c.jpg  \n",
            " extracting: test/b9402881fa580d0eb8b9b98845417550_jpg.rf.238f51ed1096107324224ade76408bdb.jpg  \n",
            " extracting: train/5cecd3b3946aac5c713a51e0bd4617c9_jpg.rf.03286d3792ba33d52a3654e14735c974.jpg  \n",
            " extracting: train/66f3c2c7c10a9263de9c6e056ba5c1b9_jpg.rf.18efa20b29dfe94acf3cb63ccc92a4b3.jpg  \n",
            " extracting: train/49d365236ee4fb6bd982b0f00bff007e_jpg.rf.16bc32d2b40baeabec00c02b2f9d0e84.jpg  \n",
            " extracting: train/0f4512d71c096f2699d705792e88fc58_jpg.rf.0971fe35ffe3ebbcc3e2a709de978aec.jpg  \n",
            " extracting: train/d0cc2420bce5b14dfd39e55dc3737e57_jpg.rf.0f1c927870242d0e614bd6e320f9969e.jpg  \n",
            " extracting: train/4d7820ad9fb4fe69d5168e1d7317dd02_jpg.rf.1279c1ccceab06443a62004f2800d891.jpg  \n",
            " extracting: train/614811e933a680fd6535ac8bf06bf530_jpg.rf.0b9ea19fb73269b21cf021c584b84aeb.jpg  \n",
            " extracting: train/36066ba85572ce99198f1a21c2c8bbff_jpg.rf.1bb4689be2417ff995fbd5e22876c353.jpg  \n",
            " extracting: train/389b4c47568c78c44df11dbb1377ffea_jpg.rf.1d6174519a8e98c853c57584e8cba891.jpg  \n",
            " extracting: test/410993714e325a1de3e394ffe860df3a_jpg.rf.ceda8f2165a9e8b314a6278acd02686f.jpg  \n",
            " extracting: train/254f92b18b2a81f88b85e7aed3cabc61_jpg.rf.09fc82bf7878065eb6cad223e60f7f0b.jpg  \n",
            " extracting: train/b0f3d66c8be13f5f6aa25b67a06bdcfa_jpg.rf.01b3f3243bf31cb2ea18a89fd58044be.jpg  \n",
            " extracting: train/3914be0cea4aa8a6bbd1081ec3b034a7_jpg.rf.1a22ac976f9598278bbbf963909a32ef.jpg  \n",
            " extracting: train/4de23afff63bc169b4ebe547a9c9b692_jpg.rf.0cf789652d85886de3d00b05bef061eb.jpg  \n",
            " extracting: train/699edbacbfee5e6d4d6d2189bc88990a_jpg.rf.21253a833a9f17c4391a96e64b279fd9.jpg  \n",
            " extracting: train/9c153a9c9798dab948d4260eb109b315_jpg.rf.04a431391f78af71e5ebaf9d51d91faf.jpg  \n",
            " extracting: train/1595777dfa66e954ae23655743e24809_jpg.rf.1ce3ed024877808c7e9f12f1f83fefae.jpg  \n",
            " extracting: train/f3a5df526393445c6e2d38f66c1f5c27_jpg.rf.09aeba93cdea53cc6a6db62f6056ec35.jpg  \n",
            " extracting: train/dd6b5c3cb2d7e77f38f1dfeb2bff0431_jpg.rf.065f8833508d101a1f1449e8fbabc314.jpg  \n",
            " extracting: test/b526b661a33ff481231d1342aff2a266_jpg.rf.dd4da31fe7f3f0eac58576f8f2c56f61.jpg  \n",
            " extracting: train/e79deba8fe520409790b601ad61da4ee_jpg.rf.016bc04dee292f80d1f975931f32bc21.jpg  \n",
            " extracting: train/889c420fb266b8d0e817306110042bda_jpg.rf.187d72f3d58f732ea576641f5c702f61.jpg  \n",
            " extracting: train/104ec0199cb67e1a359b1b0845ee66f3_jpg.rf.2148e2af0737be8e162d7d867805a8ac.jpg  \n",
            " extracting: test/654bb8835258b26c466b1c19893df451_jpg.rf.e4099f0bbd3b79210414bb32a47b437c.jpg  \n",
            " extracting: train/6179b463c8f503445e213b706d2a4de5_jpg.rf.22c6e0d7cc69bbceddc0ed8a8b0e0bc5.jpg  \n",
            " extracting: train/4d6b667ecbd41ebd603b38848366d9d0_jpg.rf.29238774d80d0be8def25571c503714f.jpg  \n",
            " extracting: train/fa4e2b9a8cf58f405f69a56c662834f2_jpg.rf.2ac2e858d136ce51bcecdc1129187214.jpg  \n",
            " extracting: train/d29148a2233950a7777285281cbfccff_jpg.rf.2e63366f947507e0735a25d532caaa54.jpg  \n",
            " extracting: train/e6e3a2ff2c75970490079f00136885ad_jpg.rf.2733f54e2f320fbc9c5e0058c731d765.jpg  \n",
            " extracting: train/37fe05bcf7d8568a9e55b569afdbccbd_jpg.rf.369f4b4dbd105056aa23957cd4be1687.jpg  \n",
            " extracting: train/1a530d578f3f0bf3497bfeff3d953025_jpg.rf.2a30081d7234f714736032af1dcb4193.jpg  \n",
            " extracting: train/9a6b61a6d3b3e3ecddc201b097aa02d1_jpg.rf.3903667901a40aedda2c42c43502d96b.jpg  \n",
            " extracting: train/ddad9dc4d945006d66f5349d64498559_jpg.rf.3d6e55223a3ce985572a9e46d7c6a9f8.jpg  \n",
            " extracting: train/675619f2c8078824cfd182cec2eeba95_jpg.rf.2a121620701a980a77942a4d8e8a813c.jpg  \n",
            " extracting: train/ea799d77875c399618c45cd9409f34ee_jpg.rf.316738a20243cf9a9a408b56ccaa5616.jpg  \n",
            " extracting: train/a8847f8fe8eaaa1c97bf83027a901760_jpg.rf.26afc5ee5c983fe73c8e113e99127fa9.jpg  \n",
            " extracting: train/26d663ab5ffbec49f9dc8e592982cfd4_jpg.rf.238eb82b4d50cc47759fa7ce82c43b97.jpg  \n",
            " extracting: train/5758322233deed7ae7adc23536db2a4f_jpg.rf.2ac5b8df5fb0e541557f79cbdd79f51a.jpg  \n",
            " extracting: train/0301b7f9ed4d5ba503fda79fc4370c29_jpg.rf.3ecfd27607406c9f46c1525efd39e17b.jpg  \n",
            " extracting: train/292b0ddcacad7de06a628980954b6993_jpg.rf.3e5a330ebaead704099fbdbcee34d96f.jpg  \n",
            " extracting: train/e8480d7fb9881d8a0e88b7be4d103f6d_jpg.rf.2bc6fa7acb94ff9b2993d2de0c7def9e.jpg  \n",
            " extracting: train/f9a9a175f26d4b26bca3a5338cc1405e_jpg.rf.378f0d92128b1608bc48d47324f380b4.jpg  \n",
            " extracting: train/cae099fe41d6aa30033d71e433c33c8d_jpg.rf.124529e05c30bf412475f20b8f274f95.jpg  \n",
            " extracting: train/8678864272a0a04c4c65ca96324105b4_jpg.rf.23c0e1b2c040efd89095760e27f28eaa.jpg  \n",
            " extracting: train/04aed88a8d23cf27e47806eb23948495_jpg.rf.4021af803b1b21022221cd3654117580.jpg  \n",
            " extracting: train/a4028b2361ce7ead654a86b07ac39d52_jpg.rf.4300592f959cf20135ac198003615490.jpg  \n",
            " extracting: train/c7890b749d14d3488066cbdfac4620fd_jpg.rf.3850673b2781e44e1a293fe12a9cde12.jpg  \n",
            " extracting: train/055b79dd8db4c43e1a23be6095aaf624_jpg.rf.3eddea89d44864ecd7971d2827ee88df.jpg  \n",
            " extracting: train/0d9dbf62d5ee42b92bf55197bba4254d_jpg.rf.3dfbde3b99d83e88daa3b69514daa68d.jpg  \n",
            " extracting: train/4bf38c062fa7b5796d15ba90d6c3a456_jpg.rf.47d09ca58c3f5cb00e286ed52ab6f29a.jpg  \n",
            " extracting: train/fa3cf2724c1648a8822b59ac0759475f_jpg.rf.3ad41d095557e6bfb446af5de5553e75.jpg  \n",
            " extracting: train/c46bf04050a2a9323dfe563e8813602f_jpg.rf.4da1d855a20ec2d0deff03a46d8363c9.jpg  \n",
            " extracting: train/6454bd04e2829d4ff83602f0f2d7154e_jpg.rf.46c9bd543815a1c9758df61f2569524e.jpg  \n",
            " extracting: train/969daa72bd7804ea1212e191820249b0_jpg.rf.42fdf983653232bcccbca70f94cbfac4.jpg  \n",
            " extracting: train/614aadadb4a7f5b475b027b8e11398ee_jpg.rf.46607639a62cb9241830db1088e145a1.jpg  \n",
            " extracting: train/3796db002cba7265bd32b0161ddd9127_jpg.rf.4f039ba64a8a26531c2b2861e04cfe7a.jpg  \n",
            " extracting: train/c76c79e40bd9839a05237934cfa89ca3_jpg.rf.498d8fcd0acd71952f9d92708b360fac.jpg  \n",
            " extracting: train/ef1d425fd5370fbf8b7adea43b755304_jpg.rf.509cd10372ad2fe7def2c49881348306.jpg  \n",
            " extracting: train/61567b97353acc18ba9e8aac0f111326_jpg.rf.5764028ed4ece48b7894801e884e111e.jpg  \n",
            " extracting: train/47e842dd95735a11cf92c0ddf1161193_jpg.rf.563bd525e9210a59e275a565317b890f.jpg  \n",
            " extracting: train/81f5c542ffe0f9eae4df59d29acbcced_jpg.rf.561b8c31b527d84832e277765b20dc4d.jpg  \n",
            " extracting: train/76dbe2ccf986a2a0d399d3d8a47279ad_jpg.rf.582fa23c9cb60c607ce4039d59257eac.jpg  \n",
            " extracting: train/eb9e7928e756c3cf9164e7afc08c4653_jpg.rf.48f982d13896a1d8c0c7a566cdde2129.jpg  \n",
            " extracting: train/f3302c754c6fd42130014199ee327d10_jpg.rf.56672ccf94cd354a96888ca0e8a8e4e0.jpg  \n",
            " extracting: train/ce54969567273b9b8a275812ff56e16c_jpg.rf.59df2edfb1d3ece93a0939c27e2ed384.jpg  \n",
            " extracting: train/23988893ef7381fece6d1ef32ef5428f_jpg.rf.5065b0683d241ad92afc074eed391b53.jpg  \n",
            " extracting: train/9d776e74e90c4f8092b060dd7567e2f8_jpg.rf.5d6deb8a1e7a40c616186a7b90f48c2b.jpg  \n",
            " extracting: train/b3b002461f1c6b432e22964549767e5f_jpg.rf.46f0298de88abcc93f279274d84d6b6b.jpg  \n",
            " extracting: train/bb54af2f0b83b174aecc29328c8fa001_jpg.rf.3224d475bfa4e44af5b808c58d411c4d.jpg  \n",
            " extracting: train/673bcd0d44f495fbe9dd88d5cacfceb3_jpg.rf.4f36394a6dc154067ad4da04cf503df8.jpg  \n",
            " extracting: train/fb586797e8ad818c7e3e3a6411f73d84_jpg.rf.52352f51cdef2f343756ef296af65d9e.jpg  \n",
            " extracting: train/2fe75c34fd54e960146fb8b0ad8b3fd6_jpg.rf.6091e6d4216ef3f71b33d14c30ec0d54.jpg  \n",
            " extracting: train/a932287da44b9dfacd0d16a5c1d27923_jpg.rf.5d4b7b1e6f3b0033a85c6fa52a0dbeef.jpg  \n",
            " extracting: train/f5231f940bcf1527ef8bb8e46ac0532b_jpg.rf.5d8200f918b607f7dbc41c8533095e41.jpg  \n",
            " extracting: train/d079f4e77b2445abceca7534356db743_jpg.rf.463c6a4e369b2ffc0baaef7ebb4a68a2.jpg  \n",
            " extracting: train/97aeb1f9b745a929e9ac0848acb53a1a_jpg.rf.5997f0ef95b45103711d4fdc239c2691.jpg  \n",
            " extracting: train/285d7c487a4e20ad832a74acb527b77f_jpg.rf.5ce3eb6a89b4c0019fde9d22a5921104.jpg  \n",
            " extracting: train/03d3ff4582c8125d69c19a72f846bec8_jpg.rf.5f77781cbc56eff8679f258ff4f7cc9f.jpg  \n",
            " extracting: train/dda052fc8dbcce6154d6874a663743eb_jpg.rf.5f2765d09b2e90e6a1d5a629a006e6ac.jpg  \n",
            " extracting: train/76e118acf05a8ebe06957f8882cc06aa_jpg.rf.6170a8b5a9733bae0c02d0ca375bde10.jpg  \n",
            " extracting: train/e40003d4bbcdac7196b9502bfe2fb6ed_jpg.rf.67e2013fa9dd32e5a94dc926ddabfd35.jpg  \n",
            " extracting: train/4ae38537a74c5ed10d5223f8066659fc_jpg.rf.4fef5c4efc7522714a483c38502f21f2.jpg  \n",
            " extracting: train/8d6f722eadc015a393bd490f9b7a85e6_jpg.rf.651f72c0d06342bd6e79bff0aeea8fd2.jpg  \n",
            " extracting: train/446e75de1ffefc2115e79696bcf0e357_jpg.rf.642c290200ecf6bac85bbde223355232.jpg  \n",
            " extracting: train/05de676d5078dc0a13796f3f627993ef_jpg.rf.70a6ddff100e5f321d7d6f8d4d977e3d.jpg  \n",
            " extracting: train/c3e9e81ba1540aae7961a4d8d96600ba_jpg.rf.65c56919cca14d00fbe5d2d44ec569de.jpg  \n",
            " extracting: train/759a86e63667ca033255c4ab438dd392_jpg.rf.708d1d10d1032312cacd959485e92fa5.jpg  \n",
            " extracting: train/d795f84f39716798482fb2937868ed8a_jpg.rf.714951561ee3a485ad7bb06fe4377bf5.jpg  \n",
            " extracting: train/99ee6574b2a7afc0bb06269bbcf49a4c_jpg.rf.693e8999d9c962ab16c457b2225359f0.jpg  \n",
            " extracting: train/5825608dccde6544eef91822136079d0_jpg.rf.62780259541cb1ed0b071c0594b71147.jpg  \n",
            " extracting: train/859e7157c6d544236a67463c08169b6e_jpg.rf.773fea93fd9593e63fedd9d27f8581a7.jpg  \n",
            " extracting: train/a5c65b40e0be3480c0ecfacaab399a87_jpg.rf.65826955144870ecaf37db65ef6532ae.jpg  \n",
            " extracting: train/d67b5b9e900409b050dd9bd594f90709_jpg.rf.7559a07ac3b4029a5a287b4b7b96ea37.jpg  \n",
            " extracting: train/b5bcde459ca36f0d1f3c20e751336672_jpg.rf.667ee729363a8d60c926d9dd3734bf2f.jpg  \n",
            " extracting: train/f587402be410b424bcbbac06e1dc6162_jpg.rf.7181098acae97a248bfa1d0586a3db69.jpg  \n",
            " extracting: train/196829feb704a34a4e471155f14bdd80_jpg.rf.7b98c9eefcd83f5cf7eea7a95e4ceba3.jpg  \n",
            " extracting: train/13106bbc80a01cc413c2ab5052d2ec25_jpg.rf.6fb6095088bd3962b78e22f736409ea5.jpg  \n",
            " extracting: train/b7a8c7de4fe1382d69f58ac97e819b5c_jpg.rf.7b795ae14bd822803c9f193def40e3ef.jpg  \n",
            " extracting: train/8d796de64b9eed1ffd5ebe550d4ca807_jpg.rf.7a9a939f45b77b1804da67fbb088c795.jpg  \n",
            " extracting: train/1877a28e4c5f5c1ea68aca66f4e85d95_jpg.rf.7d7dcb905c94e79222205feb915bafec.jpg  \n",
            " extracting: train/00bc0cacffdebe6b11bdeec56f63ee49_jpg.rf.59f0f02a28f020d480fd5d1d8aa32f6d.jpg  \n",
            " extracting: train/4667110b61b16e786673ed6126ccc35d_jpg.rf.775479ebec16606e8b47874da02463fb.jpg  \n",
            " extracting: train/03886821377011fec599e8fa12d86e89_jpg.rf.78d439f975872bc0120d597bd265684b.jpg  \n",
            " extracting: train/c0d68e012bb93c14bc333fc1d5e52621_jpg.rf.60fc27683bf9457b110251dbc3bb7c4b.jpg  \n",
            " extracting: train/4807629b8df9c7eb4366b7feccd72e6a_jpg.rf.8586b4e2e824f8ee2e108a4a32592c9d.jpg  \n",
            " extracting: train/76d01bada90581f55f1ae64c062cafcf_jpg.rf.82f338c5d9879e03d2a7455a585493e3.jpg  \n",
            " extracting: train/743665d7ef6ab0330e8786227f6f4051_jpg.rf.6482e654f2b3d8ecebfdaf396c741b07.jpg  \n",
            " extracting: train/02f0931b536dfba10affc3231a3d64fb_jpg.rf.7daf233a70122377355a36ca33e82aa4.jpg  \n",
            " extracting: train/5a8433ec79c881f84ef19a07dc73665d_jpg.rf.8c74727285683022959679af3c43f190.jpg  \n",
            " extracting: train/49c2afbbe5726160b289f7c0c62cdace_jpg.rf.88443bd77810fdde979f0d6c41bd3cc8.jpg  \n",
            " extracting: train/bc5decab88861286dcf78a367b4377cb_jpg.rf.99264d2583f17e6ba8a7b2e15c54271a.jpg  \n",
            " extracting: train/4ab3343c9e91e56813f6c36bcac9896a_jpg.rf.959e82a0ff12d5f2276016650905b3d1.jpg  \n",
            " extracting: train/9e943906fba1ec89edfacb2dd7976504_jpg.rf.9702132e48df03814384024ca7313212.jpg  \n",
            " extracting: train/edd285915356686fb53fb52c1ded0e53_jpg.rf.9e9b27a0d423c4ec63e6e1dd825d8ced.jpg  \n",
            " extracting: train/f041d3171dfe3137390c85fc5437e447_jpg.rf.8814a03f0ba5cf32468d13ff688c5594.jpg  \n",
            " extracting: train/1728cd731489df8bb8e0396e178fe393_jpg.rf.9aa607b72daa7a732ab1285f5ff96c66.jpg  \n",
            " extracting: train/b79ae5b70de58089ead6e32b235e30d3_jpg.rf.87a4a8323a2c39c2f925c7987a01d1b6.jpg  \n",
            " extracting: train/8dd12470c30e3b265e8933a6fee7ad28_jpg.rf.84b8584b870b790d4f5d40bdd24c1af4.jpg  \n",
            " extracting: train/c733616ab773817dd1a356dbbdf2ee33_jpg.rf.a3c3194c8e748b8ab26858a2646ba856.jpg  \n",
            " extracting: train/4939035108d04ee672570a7cc937e270_jpg.rf.a00ea9b7a719681055868d92c1191fe4.jpg  \n",
            " extracting: train/a4ebf4c268d80c4fe329331ea981b3a1_jpg.rf.a15a2e6dfb1ce2864f46f69bb0c54795.jpg  \n",
            " extracting: train/3474d785b1b21d68163f56aa00a92bc9_jpg.rf.7edb79a8e8ad56b74a670a5c43b5cf2a.jpg  \n",
            " extracting: train/6f0a888f9e5aed9516e336fd04723ce1_jpg.rf.9dbcc89d91a6cada0f389a0e88ecf86b.jpg  \n",
            " extracting: train/a9987cf6cc5c6545818ec294d4a5bb9b_jpg.rf.95a5bb9f3138fe997ff8faa21a85436f.jpg  \n",
            " extracting: train/d494cb268ad7f9f55587de138edc1dc4_jpg.rf.a61a3722fe947a9e22034acaaff19a8b.jpg  \n",
            " extracting: train/22e74efb18b2d88fba63d25a61bf5f97_jpg.rf.91ebc978b333aae9ba2289e894ff95c3.jpg  \n",
            " extracting: train/8de03901c64a80070048ead3fb0d32bd_jpg.rf.a81d5c2674e7d68b2245ef7725a87fac.jpg  \n",
            " extracting: train/f2672cdc28767484b556da3ab6f1003e_jpg.rf.7d0badf9505f1655f0561107d11a19f1.jpg  \n",
            " extracting: train/7df16cd59fb40e0691948cc805e4801b_jpg.rf.87b8be301feea11509703396e6f8b8e2.jpg  \n",
            " extracting: train/3bab0eaaeb63a2ac9ae4942df4006a25_jpg.rf.a637df4b9da83609e96c1828e1f4366b.jpg  \n",
            " extracting: train/92992ff9c823e0420bf17e71db9ef4ef_jpg.rf.a9c86b7daee5c7b1977507f760cdd7e8.jpg  \n",
            " extracting: train/59727dce26aaa6100078810b61404069_jpg.rf.7c04dbe505cf1bd214e4f491e3a395af.jpg  \n",
            " extracting: train/3161933dffedf8a859d6623a99492c53_jpg.rf.9267abfc68d9bd6af1912b5d0319f36c.jpg  \n",
            " extracting: train/ca869123d8a0cbcc6e54f4a445e5a78a_jpg.rf.882d99242b6bdb27680eadd4a5904cb2.jpg  \n",
            " extracting: train/f3e64e9dd12b65b941c142d142b33ef5_jpg.rf.a9db857ababa4d01d03eb09a527d29fc.jpg  \n",
            " extracting: train/2ee0fd0963465ba29d8f27c6e605c55d_jpg.rf.b0d9e857c9a56fc8077ea156fca40284.jpg  \n",
            " extracting: train/f1ea0167087976926d4fe0aa36b961ce_jpg.rf.ab4d245320384c2d04ba6e9ba6a652ec.jpg  \n",
            " extracting: train/53de0674524ae6d77bdfff48136dec2a_jpg.rf.aadf3edd69993569f90483c91fae1fca.jpg  \n",
            " extracting: train/a20eb4bb3cea2e394cfcf9ed969b628e_jpg.rf.abd0f3c626fca3ba6c4111d4fbf656ab.jpg  \n",
            " extracting: train/ec5ab1930d6aa16fff2582b48f82cada_jpg.rf.ab0666b98c1ed6aed1a7a268fdb79ec6.jpg  \n",
            " extracting: train/9146a6989dac08f1769e677064ebfb49_jpg.rf.adc60b60fd2041dbb3102a4561edf7b6.jpg  \n",
            " extracting: train/8bb72e70f0560095885586deba37a524_jpg.rf.addedc80f989194e077b8c53871457b8.jpg  \n",
            " extracting: train/f02d615907c77dc15f02bd1372e4398f_jpg.rf.b46e520760107eb69d290ac810d8e1aa.jpg  \n",
            " extracting: train/8967433350d3b3043902603430fccaab_jpg.rf.b3b6e9ca2da2674266a7d44c368a3953.jpg  \n",
            " extracting: train/383c2ed7bbe2d327ab55a871db497c33_jpg.rf.ac062d648b1833d4c5ada1dbc6052060.jpg  \n",
            " extracting: train/6bb6f7cb96bf37230681d12ff7882f61_jpg.rf.b1255adcc94141477b7d089a0b9ebf42.jpg  \n",
            " extracting: train/8ff64b3f770bfe96bdffc629efd16460_jpg.rf.b56392e0638bcb50479d4e74dad8ac8a.jpg  \n",
            " extracting: train/48e115dcbf1b3a67ca47a75a92da3f33_jpg.rf.9a3c3e55cb4a229779fc06a672af0765.jpg  \n",
            " extracting: train/4894f034a55eaa9252cd261a62b11d27_jpg.rf.bb716c1e40a670ecd703683c8dc332c0.jpg  \n",
            " extracting: train/80c787b97ed3e2b4befd6b11aa2fba37_jpg.rf.b7e9d028eb34400c5d239b57639e086e.jpg  \n",
            " extracting: train/cf2784fa97151d5316b2961b1e62dc45_jpg.rf.af04872f77bc32d96852b458e1b3597d.jpg  \n",
            " extracting: train/479459fe5c8213a84fd55ba82f2670b1_jpg.rf.c0cbd0b155916350af1e743b11766dfc.jpg  \n",
            " extracting: train/0798bfb058da59d189c1bfadcf814f29_jpg.rf.b73199953251d84e4895a862463b7964.jpg  \n",
            " extracting: train/6403b91d63799cb9b5531c47b195d088_jpg.rf.cb883855985dd9bb6c6abc4cbe53fa76.jpg  \n",
            " extracting: train/9962a4d44388b9008aa0f466e4f4052c_jpg.rf.b2b9e1236e560e47019df29344b0cc10.jpg  \n",
            " extracting: train/3730ef213ac6aad431475a9ab28f349a_jpg.rf.c18235c762e398156f5a67144b46d3a9.jpg  \n",
            " extracting: train/3e8fb24addda1a0945bd6b7777bc4018_jpg.rf.d17abcc1ddc47bcc382536d9669e3fd5.jpg  \n",
            " extracting: train/48d3c59a99b2b5a5b9f1eb7d5ba63b60_jpg.rf.c196233c6c25ec23958aa743163344b1.jpg  \n",
            " extracting: train/0cf670506bf9e0fe587647cd62caa232_jpg.rf.cc43d799dab21abc85a4368295867d8f.jpg  \n",
            " extracting: train/1b4ccdf7d5ff45dc6c3885243bde5af2_jpg.rf.c0b83419aa9e3c1b3b5a9cba2b9ea579.jpg  \n",
            " extracting: train/3091c9b25d76e9cbd0af83ced9f354e5_jpg.rf.d5f14cd80477f444b7ed601f609c67dd.jpg  \n",
            " extracting: train/5e71cb8d41c333a18e799ef0004b040c_jpg.rf.d65a0847e82174366d01e29a636074e6.jpg  \n",
            " extracting: train/4eb630d4dd38528dacf72355caf5c06d_jpg.rf.cef25bd3e5eb142ccd065e5d26049127.jpg  \n",
            " extracting: train/38f26ee82e38d332b2a831aa47bd363b_jpg.rf.ce772b291dcc390ce7786ed11a493495.jpg  \n",
            " extracting: train/b5102d7f9740eee7754ed268becb2163_jpg.rf.d4a8cfe5fa4d0f53d73c64b07ebabbce.jpg  \n",
            " extracting: train/300f80826bbb7dc4bf83e148614f2f77_jpg.rf.d2ebe06b4f53115a03fefa84f8ce7f4e.jpg  \n",
            " extracting: train/247f9cf35a263dc7dd7886b187fd5480_jpg.rf.ca7241ecf892e490f69312d56b5a6773.jpg  \n",
            " extracting: train/ec4c30d88ecc70b6a3e76dbd9b17324a_jpg.rf.da4ab525f8d9b96b4de4067bd6694cbb.jpg  \n",
            " extracting: train/9fc54a45feb5b01db8f6828d181fb075_jpg.rf.c78f29bbe2df51ae862c73f5cca0eebd.jpg  \n",
            " extracting: train/d9acc69c5d57623cda22786e309201c9_jpg.rf.dc4a82120ade321eeae8146c917e3109.jpg  \n",
            " extracting: train/8f84f1945fd993facc3368d13345f333_jpg.rf.b190d526f930a1e6e0c8568294cd2837.jpg  \n",
            " extracting: train/0b4ba28f0c759a11750a6430649b52e3_jpg.rf.c732477a7f65117e3fb24bbd7bca5b8e.jpg  \n",
            " extracting: train/79e744a68d6e6f83be0a9e8761ea66a4_jpg.rf.d796c3ba698ebf673f0d3fc42062e20c.jpg  \n",
            " extracting: train/fc9d7bc0453cb3324406401c00224d30_jpg.rf.c596d992843d8a35d80cadf5489e0770.jpg  \n",
            " extracting: train/34ad1966ae7a17d4502ca141413ed8d2_jpg.rf.dd63137d1c9d6095c293b48a0b6f3334.jpg  \n",
            " extracting: train/2c32afd520cc8bf076dfa5b6e2e1c4c1_jpg.rf.c546a535eb5f3a68ed59a794c1faeb2a.jpg  \n",
            " extracting: train/0115e4df73475b550e5c6f7a88b2474f_jpg.rf.dfa577bd4af5440d689046c2f48bc48e.jpg  \n",
            " extracting: train/57def88c6de500f5f6926354b3680a13_jpg.rf.dd74421d7ddaa3ec1198e12a84a9f1dc.jpg  \n",
            " extracting: train/998222d9c93f1640829d4f0032dbf3e8_jpg.rf.dfdbeef166796c8f4327b3a456ca1cfe.jpg  \n",
            " extracting: train/6f0de9b594de9f9b92c6a20daa51a28a_jpg.rf.e7362c0e232dfa07aa0eb3f52bb4fd50.jpg  \n",
            " extracting: train/3057eba7e9b0221ddbdc96a01f39ab79_jpg.rf.f5ca64930fd980c194483c8a3bb6a54e.jpg  \n",
            " extracting: train/31419854b103ca6becc4cc394c449e95_jpg.rf.ed358e1365d7de3a15257d87752c51b9.jpg  \n",
            " extracting: train/9504fb6b81031feac1fbf1e128b5c173_jpg.rf.e4e7ce142edc55c73267abbe60ec69b3.jpg  \n",
            " extracting: train/c3e3b51f63d344be346e6e425f30f87a_jpg.rf.f88e789167d309e0381aa2c9d4a6e322.jpg  \n",
            " extracting: train/d3a4e1b8f13ef89f419251f5c5839d0d_jpg.rf.e4b5ce214ea2670fa96ab949aec57dcc.jpg  \n",
            " extracting: train/7ee8d13861bdc45e40a7cfe190a8d8a6_jpg.rf.f89633224312e1c80ce73c4e05c65051.jpg  \n",
            " extracting: train/65ba27557c78850168b1df70a3ce4ff7_jpg.rf.ef005cf77310609923ff2fb962581194.jpg  \n",
            " extracting: train/6589f4cfb37439d7d276f0d70f7ee1f0_jpg.rf.e6bfa3034bc8005aaadf8ba1aca18e61.jpg  \n",
            " extracting: train/1a8a4abcba7c4ead35c01f05b9fae8e5_jpg.rf.e36b61dd77198f5d2ffd5c39645638cb.jpg  \n",
            " extracting: train/f52e1873b8583f8bf4f7ddf6e9649f07_jpg.rf.e9f936cd405597e058a5d399d094078d.jpg  \n",
            " extracting: train/d415969922564f317be0d1433330626f_jpg.rf.ec44988c2ee838f90f37cc64ea149905.jpg  \n",
            " extracting: train/9c5fb0c3cfd7b334a247cd87c139e8e6_jpg.rf.e515316111e554f86ea49e12faeda7a4.jpg  \n",
            " extracting: train/beb11566e59775b61f0ca369952067cc_jpg.rf.f2f174dcc0acd5991b822c5ca1a6735a.jpg  \n",
            " extracting: train/49f78dc9aaeadd0c76ed2def75c358f3_jpg.rf.ebe11640761df4735fa11bf2516c7967.jpg  \n",
            " extracting: train/239c409d5c09b493fed01a70a3cda4bc_jpg.rf.f8f5bf822dba445148cf5271f1a7e34d.jpg  \n",
            " extracting: train/d33c33de41dbe1a95a43212c58fd12b7_jpg.rf.fca260fa864f5898d61bee78b5f152e1.jpg  \n",
            " extracting: train/a9768de3fceeeae2618f362870fb9a88_jpg.rf.f08a04590fba92deafdb3def03e97c44.jpg  \n",
            " extracting: train/040f2bcba5afce3afafdd5bbf36d2ca5_jpg.rf.fe6d0720247b60f2c6e1cda98fd00cab.jpg  \n",
            " extracting: train/54a90aab8c73562975cc560d51a9d2d1_jpg.rf.f5700e30dc924ed32d1b7e34cff05c04.jpg  \n",
            " extracting: train/06770ce99d4866165c0dfb104179c361_jpg.rf.e7acda724f1beddf07e9cc9ee750f3d5.jpg  \n",
            " extracting: train/de60ba81aa78387928e4bdc11f3be301_jpg.rf.e7b8966eca79a6758f9f2eedfcf1177c.jpg  \n",
            " extracting: train/e4209b257f3706992c059c836cc42ec7_jpg.rf.ed76056e3061801af1c2cdf46bea57fc.jpg  \n",
            " extracting: train/93557fc861304f7753089c244bc1e33e_jpg.rf.ffbb0460f28c29ea6c2f0e5ff165550c.jpg  \n",
            " extracting: train/871597c145446cf58c1c2dd7db988864_jpg.rf.dfe014e3493447cc19e30bb97c00239a.jpg  \n",
            " extracting: valid/55be99616328f83dcbfe8c18e1387c0e_jpg.rf.36754078c78920a961830dfaaf13e0a6.jpg  \n",
            " extracting: valid/fb7d97265a22bb1c1f908dadc6f9e7dc_jpg.rf.2bb7d12a905737aefab726bddf073b15.jpg  \n",
            " extracting: valid/8ec14357f5f18fb98db86e0283623150_jpg.rf.336c6e5901f05467bb6b35b785a73949.jpg  \n",
            " extracting: valid/c20ca9283ea51ac7707905894a7da703_jpg.rf.365ea9253c49e1145082f3893571bc9a.jpg  \n",
            " extracting: valid/c5172afbdad90854b3d0f21a923c0c69_jpg.rf.6645c6f01feff2a87722629cb9ab963a.jpg  \n",
            " extracting: valid/793c79d55c8a252b7a954d074b1d6498_jpg.rf.3af5b0c88f75574c8733ad6a9a511285.jpg  \n",
            " extracting: valid/0c09b79cff39932c59ecc745dd827906_jpg.rf.24b462cfe4b4e7dba97d478de07b9115.jpg  \n",
            " extracting: valid/6a41b6c8201604216ad196f842c6a2c6_jpg.rf.0d52407ef16693d64cff0668cf321247.jpg  \n",
            " extracting: valid/0af4c8f0fb5d899e9d1c8d34b2efa980_jpg.rf.57b0654146d453d6cae13cdddc229aa2.jpg  \n",
            " extracting: train/6ba74e310dd824af891d057d674cedb9_jpg.rf.f100b00ae7151f33ca508ed17be6e7c6.jpg  \n",
            " extracting: valid/c1f800417bc42263d141b5ed785e7707_jpg.rf.392e40659901da081aa711c6e9a59af8.jpg  \n",
            " extracting: valid/6e2dd4604b3a51d9be11b8809ed03803_jpg.rf.667ebfe34e7fa7194e71635b3364dcbb.jpg  \n",
            " extracting: valid/3e0c67f38992fe16dfc163f7f5336263_jpg.rf.4d79300bd37d2259d21ba88499057193.jpg  \n",
            " extracting: valid/e53bf8a0e692a4ccd5f1dc2bc19e7751_jpg.rf.469657a97d400016f17a01731956ed43.jpg  \n",
            " extracting: valid/9453c2097cb4ccc676e273939894b3da_jpg.rf.66f387eef4e1095bd8ceb9bf80829208.jpg  \n",
            " extracting: valid/18742c87a03866e042c5659ba04d1180_jpg.rf.4424e6a8a441a8389fa7d8691955c4c4.jpg  \n",
            " extracting: valid/1be2a621f309c7482e9a79ad5b23ecbe_jpg.rf.5110719a49957c38e3e509c0f644ee8a.jpg  \n",
            " extracting: valid/31b83afa654d5dd874c3f0111126ab7f_jpg.rf.578d68b987125c78d5974e1ba6384358.jpg  \n",
            " extracting: valid/05ad7223827a29a8283f6c4b2490f52f_jpg.rf.5039e263463db5153a0dd8439b462588.jpg  \n",
            " extracting: valid/4b8f93069270a9f7bb523518a5088b9e_jpg.rf.7d625433b528e65c579f62eee62b0847.jpg  \n",
            " extracting: valid/abd65798d9952a27e087710eb8bddf32_jpg.rf.4a213f8a0a18bbd6a6445a5c78b72846.jpg  \n",
            " extracting: valid/aec1aa6773dbbe004554f405cdef2bea_jpg.rf.7c2ac24381a7b22374523a201c21467c.jpg  \n",
            " extracting: valid/688232b6869708fe78907898f8f8b5f9_jpg.rf.6bb2e677c81378bf20e3e43710e505e9.jpg  \n",
            " extracting: valid/7e97f49e613a59a70b833e4c0b2c1c04_jpg.rf.84c0d1ef94637613ccabfb825d647a41.jpg  \n",
            " extracting: valid/3baf85c957b9d28a16c0b65cb2ef0d29_jpg.rf.825ae30ea5a63347bf69def9d1963bcb.jpg  \n",
            " extracting: valid/64061fd2e0e35bdf9ac4681eddf5fa2a_jpg.rf.6857b7f054d184aa9404720b55f05a2b.jpg  \n",
            " extracting: valid/5d492613cf4021eb387513e2635cb3aa_jpg.rf.8ea3718b5ca86bbaeadf248887f74fdf.jpg  \n",
            " extracting: valid/424d6506342fa2471e71586675ed092c_jpg.rf.988e7de42f51f3f688417fa6b924af55.jpg  \n",
            " extracting: valid/ff33a2df1da63c736d4cf28473d3c220_jpg.rf.4e74afa93891c4a01b95784eb9a9268d.jpg  \n",
            " extracting: valid/578029c06939a788cd5606ad17b49fb9_jpg.rf.22a4229d97b9d564fcb42140b375c401.jpg  \n",
            " extracting: valid/0d9afc3d23392c3958f53d7fe71fd2f1_jpg.rf.907162426130ed7370ad72200fdd3bc0.jpg  \n",
            " extracting: valid/eca42980852e6c5db10ee84aac23f9c6_jpg.rf.746317745a1bb86f4da60bfd8eb2db36.jpg  \n",
            " extracting: valid/d9e1d53f5e3a4433421dcd591f76f869_jpg.rf.83b108a81003f948521c89774adc87f3.jpg  \n",
            " extracting: valid/33b66ede234715fb46db40b33c4e26c1_jpg.rf.6d0e742174ceaac44bb8796a960f9236.jpg  \n",
            " extracting: valid/3aafc2d38807dddd1b43a54cb70f500d_jpg.rf.561ea7a7774fc0087608ace4aa379998.jpg  \n",
            " extracting: valid/e7edc4f1b8d3cc1069b96d0358e066c9_jpg.rf.a3de5df2eba3d7ce93e6f4bc5f9d8f3f.jpg  \n",
            " extracting: valid/7e862b85e33cd247ed66447d129e5fb4_jpg.rf.abee398f18046b4d243ac69d762138a2.jpg  \n",
            " extracting: valid/d6e283a49b0395a6d5867c9e98e32045_jpg.rf.98019c4213f1dfdb5e6ad1650216f5b6.jpg  \n",
            " extracting: valid/bb0de9761d16eee258ae09d8de32002c_jpg.rf.c27c48aeaf45d2b9cd8aa28ce82f5209.jpg  \n",
            " extracting: valid/26fa37995fa5b18ec40e0a94e6d91104_jpg.rf.ae716df13c86ffbaf972aed9fa4e08ef.jpg  \n",
            " extracting: valid/495019998442ddf85b59e387d4916cd3_jpg.rf.ba08d9a498ecad855a31f6c64f7ffa96.jpg  \n",
            " extracting: valid/15cc23c777b00d0e123f9df468f2852b_jpg.rf.69a7ec25c26ca626a9c3d3455989715a.jpg  \n",
            " extracting: valid/0b2252c93c53e1b2e61d485b22328e2e_jpg.rf.c61f1858920b2e783ee048a397a59d02.jpg  \n",
            " extracting: valid/5c19d3260762f5daa632d952bc0074d6_jpg.rf.ae475688a20af8344bcd8d9b7e37e853.jpg  \n",
            " extracting: valid/97ed198b00b5491747d3b425df8e7096_jpg.rf.aeabc0f0f9a1bb963c3001f4903ac38a.jpg  \n",
            " extracting: valid/d114edc5cb4cae0ceb2f152afd15f57d_jpg.rf.a47ecb8ab8be13c4449100793c00ba58.jpg  \n",
            " extracting: valid/1b7c1c9570e900f75eb974f99cbb3c60_jpg.rf.cf50b35db1eb4d6232850d24c5187794.jpg  \n",
            " extracting: valid/73e6a751c50604d017541c11b28d8417_jpg.rf.be0202c45e3c0e0936cfa30813f88d6f.jpg  \n",
            " extracting: valid/d9ef98145d7d35393c75a51331a20e2c_jpg.rf.d045b29b13d25132e1f7b23a02161819.jpg  \n",
            " extracting: valid/d4f7caf01359b9a757c930140f746fad_jpg.rf.ccdaecd58d74f3bc49babbde826e2e60.jpg  \n",
            " extracting: valid/ec418cafd39d7c5a69cc0642a08b2a08_jpg.rf.f246d01cc6a67541b8a6d383c197e7dc.jpg  \n",
            " extracting: valid/302e7c10664be32b4fc000452149027c_jpg.rf.cc08ac2db1a22e4b2d0ce14f66015dce.jpg  \n",
            " extracting: valid/57d1d1fb35ed875f9e770660bb03b6d7_jpg.rf.ee46450ad0ef6a5c64d977a5f1c755f2.jpg  \n",
            " extracting: valid/3312e3bb60e338e9c1a614f0f8960dd8_jpg.rf.cc13ce4af944d2aeb4afaa7959fd72fd.jpg  \n",
            " extracting: valid/6859628a422c1b72be8b074841cd943e_jpg.rf.dc8c083b42296b8c70664349805d98f3.jpg  \n",
            " extracting: valid/86afe95de5471af5cef08e6ae4d9acbb_jpg.rf.c90d58d63f997b978c67626c194fc2bd.jpg  \n",
            " extracting: valid/e1616dc9962fed075576ac4ea3553f51_jpg.rf.de48bd9b3a1fbb4e967dc60f36fabce6.jpg  \n",
            " extracting: valid/d3b9309d00a2b671407b918ea867a935_jpg.rf.9d8fcbced3aa4c09446abb6ed0c29233.jpg  \n",
            " extracting: valid/ca6484c259f286c5bdf1afefc868b753_jpg.rf.af40757deb44de14e90bf3a76b070028.jpg  \n",
            " extracting: test/_annotations.txt   \n",
            " extracting: test/_classes.txt       \n",
            " extracting: train/_annotations.txt  \n",
            " extracting: train/_classes.txt      \n",
            " extracting: valid/_annotations.txt  \n",
            " extracting: valid/_classes.txt      \n",
            " extracting: README.roboflow.txt     \n",
            " extracting: README.dataset.txt      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izGzSaeJzqAl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "c3f4451b-64eb-4d31-9b2b-484a6c81abaa"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "coco_annotation.py  \u001b[0m\u001b[01;34mmodel_data\u001b[0m/          train_bottleneck.py  yolo.py\n",
            "convert.py          README.dataset.txt   train.py             yolov3.cfg\n",
            "darknet53.cfg       README.md            Tutorial.ipynb       yolov3-tiny.cfg\n",
            "\u001b[01;34mfont\u001b[0m/               README.roboflow.txt  \u001b[01;34mvalid\u001b[0m/               yolo_video.py\n",
            "kmeans.py           \u001b[01;34mtest\u001b[0m/                voc_annotation.py\n",
            "LICENSE             \u001b[01;34mtrain\u001b[0m/               \u001b[01;34myolo3\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1PagPopmUIG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "52a49192-e6fc-4185-b66d-fe85a4ef983b"
      },
      "source": [
        "# change directory into our export folder from Roboflow\n",
        "%cd train"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-yolo3/train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ372c7gWN_p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "25d96472-e563-4d7d-f2d3-430741da046d"
      },
      "source": [
        "# show what came with the Roboflow export\n",
        "%ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00bc0cacffdebe6b11bdeec56f63ee49_jpg.rf.59f0f02a28f020d480fd5d1d8aa32f6d.jpg\n",
            "0115e4df73475b550e5c6f7a88b2474f_jpg.rf.dfa577bd4af5440d689046c2f48bc48e.jpg\n",
            "02f0931b536dfba10affc3231a3d64fb_jpg.rf.7daf233a70122377355a36ca33e82aa4.jpg\n",
            "0301b7f9ed4d5ba503fda79fc4370c29_jpg.rf.3ecfd27607406c9f46c1525efd39e17b.jpg\n",
            "03886821377011fec599e8fa12d86e89_jpg.rf.78d439f975872bc0120d597bd265684b.jpg\n",
            "03d3ff4582c8125d69c19a72f846bec8_jpg.rf.5f77781cbc56eff8679f258ff4f7cc9f.jpg\n",
            "040f2bcba5afce3afafdd5bbf36d2ca5_jpg.rf.fe6d0720247b60f2c6e1cda98fd00cab.jpg\n",
            "04aed88a8d23cf27e47806eb23948495_jpg.rf.4021af803b1b21022221cd3654117580.jpg\n",
            "055b79dd8db4c43e1a23be6095aaf624_jpg.rf.3eddea89d44864ecd7971d2827ee88df.jpg\n",
            "05de676d5078dc0a13796f3f627993ef_jpg.rf.70a6ddff100e5f321d7d6f8d4d977e3d.jpg\n",
            "06770ce99d4866165c0dfb104179c361_jpg.rf.e7acda724f1beddf07e9cc9ee750f3d5.jpg\n",
            "0798bfb058da59d189c1bfadcf814f29_jpg.rf.b73199953251d84e4895a862463b7964.jpg\n",
            "0b4ba28f0c759a11750a6430649b52e3_jpg.rf.c732477a7f65117e3fb24bbd7bca5b8e.jpg\n",
            "0cf670506bf9e0fe587647cd62caa232_jpg.rf.cc43d799dab21abc85a4368295867d8f.jpg\n",
            "0d9dbf62d5ee42b92bf55197bba4254d_jpg.rf.3dfbde3b99d83e88daa3b69514daa68d.jpg\n",
            "0f4512d71c096f2699d705792e88fc58_jpg.rf.0971fe35ffe3ebbcc3e2a709de978aec.jpg\n",
            "104ec0199cb67e1a359b1b0845ee66f3_jpg.rf.2148e2af0737be8e162d7d867805a8ac.jpg\n",
            "13106bbc80a01cc413c2ab5052d2ec25_jpg.rf.6fb6095088bd3962b78e22f736409ea5.jpg\n",
            "1595777dfa66e954ae23655743e24809_jpg.rf.1ce3ed024877808c7e9f12f1f83fefae.jpg\n",
            "1728cd731489df8bb8e0396e178fe393_jpg.rf.9aa607b72daa7a732ab1285f5ff96c66.jpg\n",
            "1877a28e4c5f5c1ea68aca66f4e85d95_jpg.rf.7d7dcb905c94e79222205feb915bafec.jpg\n",
            "196829feb704a34a4e471155f14bdd80_jpg.rf.7b98c9eefcd83f5cf7eea7a95e4ceba3.jpg\n",
            "1a530d578f3f0bf3497bfeff3d953025_jpg.rf.2a30081d7234f714736032af1dcb4193.jpg\n",
            "1a8a4abcba7c4ead35c01f05b9fae8e5_jpg.rf.e36b61dd77198f5d2ffd5c39645638cb.jpg\n",
            "1b4ccdf7d5ff45dc6c3885243bde5af2_jpg.rf.c0b83419aa9e3c1b3b5a9cba2b9ea579.jpg\n",
            "22e74efb18b2d88fba63d25a61bf5f97_jpg.rf.91ebc978b333aae9ba2289e894ff95c3.jpg\n",
            "23988893ef7381fece6d1ef32ef5428f_jpg.rf.5065b0683d241ad92afc074eed391b53.jpg\n",
            "239c409d5c09b493fed01a70a3cda4bc_jpg.rf.f8f5bf822dba445148cf5271f1a7e34d.jpg\n",
            "247f9cf35a263dc7dd7886b187fd5480_jpg.rf.ca7241ecf892e490f69312d56b5a6773.jpg\n",
            "254f92b18b2a81f88b85e7aed3cabc61_jpg.rf.09fc82bf7878065eb6cad223e60f7f0b.jpg\n",
            "26d663ab5ffbec49f9dc8e592982cfd4_jpg.rf.238eb82b4d50cc47759fa7ce82c43b97.jpg\n",
            "285d7c487a4e20ad832a74acb527b77f_jpg.rf.5ce3eb6a89b4c0019fde9d22a5921104.jpg\n",
            "292b0ddcacad7de06a628980954b6993_jpg.rf.3e5a330ebaead704099fbdbcee34d96f.jpg\n",
            "2c32afd520cc8bf076dfa5b6e2e1c4c1_jpg.rf.c546a535eb5f3a68ed59a794c1faeb2a.jpg\n",
            "2ee0fd0963465ba29d8f27c6e605c55d_jpg.rf.b0d9e857c9a56fc8077ea156fca40284.jpg\n",
            "2fe75c34fd54e960146fb8b0ad8b3fd6_jpg.rf.6091e6d4216ef3f71b33d14c30ec0d54.jpg\n",
            "300f80826bbb7dc4bf83e148614f2f77_jpg.rf.d2ebe06b4f53115a03fefa84f8ce7f4e.jpg\n",
            "3057eba7e9b0221ddbdc96a01f39ab79_jpg.rf.f5ca64930fd980c194483c8a3bb6a54e.jpg\n",
            "3091c9b25d76e9cbd0af83ced9f354e5_jpg.rf.d5f14cd80477f444b7ed601f609c67dd.jpg\n",
            "31419854b103ca6becc4cc394c449e95_jpg.rf.ed358e1365d7de3a15257d87752c51b9.jpg\n",
            "3161933dffedf8a859d6623a99492c53_jpg.rf.9267abfc68d9bd6af1912b5d0319f36c.jpg\n",
            "3474d785b1b21d68163f56aa00a92bc9_jpg.rf.7edb79a8e8ad56b74a670a5c43b5cf2a.jpg\n",
            "34ad1966ae7a17d4502ca141413ed8d2_jpg.rf.dd63137d1c9d6095c293b48a0b6f3334.jpg\n",
            "36066ba85572ce99198f1a21c2c8bbff_jpg.rf.1bb4689be2417ff995fbd5e22876c353.jpg\n",
            "3730ef213ac6aad431475a9ab28f349a_jpg.rf.c18235c762e398156f5a67144b46d3a9.jpg\n",
            "3796db002cba7265bd32b0161ddd9127_jpg.rf.4f039ba64a8a26531c2b2861e04cfe7a.jpg\n",
            "37fe05bcf7d8568a9e55b569afdbccbd_jpg.rf.369f4b4dbd105056aa23957cd4be1687.jpg\n",
            "383c2ed7bbe2d327ab55a871db497c33_jpg.rf.ac062d648b1833d4c5ada1dbc6052060.jpg\n",
            "389b4c47568c78c44df11dbb1377ffea_jpg.rf.1d6174519a8e98c853c57584e8cba891.jpg\n",
            "38f26ee82e38d332b2a831aa47bd363b_jpg.rf.ce772b291dcc390ce7786ed11a493495.jpg\n",
            "3914be0cea4aa8a6bbd1081ec3b034a7_jpg.rf.1a22ac976f9598278bbbf963909a32ef.jpg\n",
            "3bab0eaaeb63a2ac9ae4942df4006a25_jpg.rf.a637df4b9da83609e96c1828e1f4366b.jpg\n",
            "3e8fb24addda1a0945bd6b7777bc4018_jpg.rf.d17abcc1ddc47bcc382536d9669e3fd5.jpg\n",
            "446e75de1ffefc2115e79696bcf0e357_jpg.rf.642c290200ecf6bac85bbde223355232.jpg\n",
            "4667110b61b16e786673ed6126ccc35d_jpg.rf.775479ebec16606e8b47874da02463fb.jpg\n",
            "479459fe5c8213a84fd55ba82f2670b1_jpg.rf.c0cbd0b155916350af1e743b11766dfc.jpg\n",
            "47e842dd95735a11cf92c0ddf1161193_jpg.rf.563bd525e9210a59e275a565317b890f.jpg\n",
            "4807629b8df9c7eb4366b7feccd72e6a_jpg.rf.8586b4e2e824f8ee2e108a4a32592c9d.jpg\n",
            "4894f034a55eaa9252cd261a62b11d27_jpg.rf.bb716c1e40a670ecd703683c8dc332c0.jpg\n",
            "48d3c59a99b2b5a5b9f1eb7d5ba63b60_jpg.rf.c196233c6c25ec23958aa743163344b1.jpg\n",
            "48e115dcbf1b3a67ca47a75a92da3f33_jpg.rf.9a3c3e55cb4a229779fc06a672af0765.jpg\n",
            "4939035108d04ee672570a7cc937e270_jpg.rf.a00ea9b7a719681055868d92c1191fe4.jpg\n",
            "49c2afbbe5726160b289f7c0c62cdace_jpg.rf.88443bd77810fdde979f0d6c41bd3cc8.jpg\n",
            "49d365236ee4fb6bd982b0f00bff007e_jpg.rf.16bc32d2b40baeabec00c02b2f9d0e84.jpg\n",
            "49f78dc9aaeadd0c76ed2def75c358f3_jpg.rf.ebe11640761df4735fa11bf2516c7967.jpg\n",
            "4ab3343c9e91e56813f6c36bcac9896a_jpg.rf.959e82a0ff12d5f2276016650905b3d1.jpg\n",
            "4ae38537a74c5ed10d5223f8066659fc_jpg.rf.4fef5c4efc7522714a483c38502f21f2.jpg\n",
            "4bf38c062fa7b5796d15ba90d6c3a456_jpg.rf.47d09ca58c3f5cb00e286ed52ab6f29a.jpg\n",
            "4d6b667ecbd41ebd603b38848366d9d0_jpg.rf.29238774d80d0be8def25571c503714f.jpg\n",
            "4d7820ad9fb4fe69d5168e1d7317dd02_jpg.rf.1279c1ccceab06443a62004f2800d891.jpg\n",
            "4de23afff63bc169b4ebe547a9c9b692_jpg.rf.0cf789652d85886de3d00b05bef061eb.jpg\n",
            "4eb630d4dd38528dacf72355caf5c06d_jpg.rf.cef25bd3e5eb142ccd065e5d26049127.jpg\n",
            "53de0674524ae6d77bdfff48136dec2a_jpg.rf.aadf3edd69993569f90483c91fae1fca.jpg\n",
            "54a90aab8c73562975cc560d51a9d2d1_jpg.rf.f5700e30dc924ed32d1b7e34cff05c04.jpg\n",
            "5758322233deed7ae7adc23536db2a4f_jpg.rf.2ac5b8df5fb0e541557f79cbdd79f51a.jpg\n",
            "57def88c6de500f5f6926354b3680a13_jpg.rf.dd74421d7ddaa3ec1198e12a84a9f1dc.jpg\n",
            "5825608dccde6544eef91822136079d0_jpg.rf.62780259541cb1ed0b071c0594b71147.jpg\n",
            "59727dce26aaa6100078810b61404069_jpg.rf.7c04dbe505cf1bd214e4f491e3a395af.jpg\n",
            "5a8433ec79c881f84ef19a07dc73665d_jpg.rf.8c74727285683022959679af3c43f190.jpg\n",
            "5cecd3b3946aac5c713a51e0bd4617c9_jpg.rf.03286d3792ba33d52a3654e14735c974.jpg\n",
            "5e71cb8d41c333a18e799ef0004b040c_jpg.rf.d65a0847e82174366d01e29a636074e6.jpg\n",
            "614811e933a680fd6535ac8bf06bf530_jpg.rf.0b9ea19fb73269b21cf021c584b84aeb.jpg\n",
            "614aadadb4a7f5b475b027b8e11398ee_jpg.rf.46607639a62cb9241830db1088e145a1.jpg\n",
            "61567b97353acc18ba9e8aac0f111326_jpg.rf.5764028ed4ece48b7894801e884e111e.jpg\n",
            "6179b463c8f503445e213b706d2a4de5_jpg.rf.22c6e0d7cc69bbceddc0ed8a8b0e0bc5.jpg\n",
            "6403b91d63799cb9b5531c47b195d088_jpg.rf.cb883855985dd9bb6c6abc4cbe53fa76.jpg\n",
            "6454bd04e2829d4ff83602f0f2d7154e_jpg.rf.46c9bd543815a1c9758df61f2569524e.jpg\n",
            "6589f4cfb37439d7d276f0d70f7ee1f0_jpg.rf.e6bfa3034bc8005aaadf8ba1aca18e61.jpg\n",
            "65ba27557c78850168b1df70a3ce4ff7_jpg.rf.ef005cf77310609923ff2fb962581194.jpg\n",
            "66f3c2c7c10a9263de9c6e056ba5c1b9_jpg.rf.18efa20b29dfe94acf3cb63ccc92a4b3.jpg\n",
            "673bcd0d44f495fbe9dd88d5cacfceb3_jpg.rf.4f36394a6dc154067ad4da04cf503df8.jpg\n",
            "675619f2c8078824cfd182cec2eeba95_jpg.rf.2a121620701a980a77942a4d8e8a813c.jpg\n",
            "699edbacbfee5e6d4d6d2189bc88990a_jpg.rf.21253a833a9f17c4391a96e64b279fd9.jpg\n",
            "6ba74e310dd824af891d057d674cedb9_jpg.rf.f100b00ae7151f33ca508ed17be6e7c6.jpg\n",
            "6bb6f7cb96bf37230681d12ff7882f61_jpg.rf.b1255adcc94141477b7d089a0b9ebf42.jpg\n",
            "6f0a888f9e5aed9516e336fd04723ce1_jpg.rf.9dbcc89d91a6cada0f389a0e88ecf86b.jpg\n",
            "6f0de9b594de9f9b92c6a20daa51a28a_jpg.rf.e7362c0e232dfa07aa0eb3f52bb4fd50.jpg\n",
            "743665d7ef6ab0330e8786227f6f4051_jpg.rf.6482e654f2b3d8ecebfdaf396c741b07.jpg\n",
            "759a86e63667ca033255c4ab438dd392_jpg.rf.708d1d10d1032312cacd959485e92fa5.jpg\n",
            "76d01bada90581f55f1ae64c062cafcf_jpg.rf.82f338c5d9879e03d2a7455a585493e3.jpg\n",
            "76dbe2ccf986a2a0d399d3d8a47279ad_jpg.rf.582fa23c9cb60c607ce4039d59257eac.jpg\n",
            "76e118acf05a8ebe06957f8882cc06aa_jpg.rf.6170a8b5a9733bae0c02d0ca375bde10.jpg\n",
            "79e744a68d6e6f83be0a9e8761ea66a4_jpg.rf.d796c3ba698ebf673f0d3fc42062e20c.jpg\n",
            "7df16cd59fb40e0691948cc805e4801b_jpg.rf.87b8be301feea11509703396e6f8b8e2.jpg\n",
            "7ee8d13861bdc45e40a7cfe190a8d8a6_jpg.rf.f89633224312e1c80ce73c4e05c65051.jpg\n",
            "80c787b97ed3e2b4befd6b11aa2fba37_jpg.rf.b7e9d028eb34400c5d239b57639e086e.jpg\n",
            "81f5c542ffe0f9eae4df59d29acbcced_jpg.rf.561b8c31b527d84832e277765b20dc4d.jpg\n",
            "859e7157c6d544236a67463c08169b6e_jpg.rf.773fea93fd9593e63fedd9d27f8581a7.jpg\n",
            "8678864272a0a04c4c65ca96324105b4_jpg.rf.23c0e1b2c040efd89095760e27f28eaa.jpg\n",
            "871597c145446cf58c1c2dd7db988864_jpg.rf.dfe014e3493447cc19e30bb97c00239a.jpg\n",
            "889c420fb266b8d0e817306110042bda_jpg.rf.187d72f3d58f732ea576641f5c702f61.jpg\n",
            "8967433350d3b3043902603430fccaab_jpg.rf.b3b6e9ca2da2674266a7d44c368a3953.jpg\n",
            "8bb72e70f0560095885586deba37a524_jpg.rf.addedc80f989194e077b8c53871457b8.jpg\n",
            "8d6f722eadc015a393bd490f9b7a85e6_jpg.rf.651f72c0d06342bd6e79bff0aeea8fd2.jpg\n",
            "8d796de64b9eed1ffd5ebe550d4ca807_jpg.rf.7a9a939f45b77b1804da67fbb088c795.jpg\n",
            "8dd12470c30e3b265e8933a6fee7ad28_jpg.rf.84b8584b870b790d4f5d40bdd24c1af4.jpg\n",
            "8de03901c64a80070048ead3fb0d32bd_jpg.rf.a81d5c2674e7d68b2245ef7725a87fac.jpg\n",
            "8f84f1945fd993facc3368d13345f333_jpg.rf.b190d526f930a1e6e0c8568294cd2837.jpg\n",
            "8ff64b3f770bfe96bdffc629efd16460_jpg.rf.b56392e0638bcb50479d4e74dad8ac8a.jpg\n",
            "9146a6989dac08f1769e677064ebfb49_jpg.rf.adc60b60fd2041dbb3102a4561edf7b6.jpg\n",
            "92992ff9c823e0420bf17e71db9ef4ef_jpg.rf.a9c86b7daee5c7b1977507f760cdd7e8.jpg\n",
            "93557fc861304f7753089c244bc1e33e_jpg.rf.ffbb0460f28c29ea6c2f0e5ff165550c.jpg\n",
            "9504fb6b81031feac1fbf1e128b5c173_jpg.rf.e4e7ce142edc55c73267abbe60ec69b3.jpg\n",
            "969daa72bd7804ea1212e191820249b0_jpg.rf.42fdf983653232bcccbca70f94cbfac4.jpg\n",
            "97aeb1f9b745a929e9ac0848acb53a1a_jpg.rf.5997f0ef95b45103711d4fdc239c2691.jpg\n",
            "9962a4d44388b9008aa0f466e4f4052c_jpg.rf.b2b9e1236e560e47019df29344b0cc10.jpg\n",
            "998222d9c93f1640829d4f0032dbf3e8_jpg.rf.dfdbeef166796c8f4327b3a456ca1cfe.jpg\n",
            "99ee6574b2a7afc0bb06269bbcf49a4c_jpg.rf.693e8999d9c962ab16c457b2225359f0.jpg\n",
            "9a6b61a6d3b3e3ecddc201b097aa02d1_jpg.rf.3903667901a40aedda2c42c43502d96b.jpg\n",
            "9c153a9c9798dab948d4260eb109b315_jpg.rf.04a431391f78af71e5ebaf9d51d91faf.jpg\n",
            "9c5fb0c3cfd7b334a247cd87c139e8e6_jpg.rf.e515316111e554f86ea49e12faeda7a4.jpg\n",
            "9d776e74e90c4f8092b060dd7567e2f8_jpg.rf.5d6deb8a1e7a40c616186a7b90f48c2b.jpg\n",
            "9e943906fba1ec89edfacb2dd7976504_jpg.rf.9702132e48df03814384024ca7313212.jpg\n",
            "9fc54a45feb5b01db8f6828d181fb075_jpg.rf.c78f29bbe2df51ae862c73f5cca0eebd.jpg\n",
            "a20eb4bb3cea2e394cfcf9ed969b628e_jpg.rf.abd0f3c626fca3ba6c4111d4fbf656ab.jpg\n",
            "a4028b2361ce7ead654a86b07ac39d52_jpg.rf.4300592f959cf20135ac198003615490.jpg\n",
            "a4ebf4c268d80c4fe329331ea981b3a1_jpg.rf.a15a2e6dfb1ce2864f46f69bb0c54795.jpg\n",
            "a5c65b40e0be3480c0ecfacaab399a87_jpg.rf.65826955144870ecaf37db65ef6532ae.jpg\n",
            "a8847f8fe8eaaa1c97bf83027a901760_jpg.rf.26afc5ee5c983fe73c8e113e99127fa9.jpg\n",
            "a932287da44b9dfacd0d16a5c1d27923_jpg.rf.5d4b7b1e6f3b0033a85c6fa52a0dbeef.jpg\n",
            "a9768de3fceeeae2618f362870fb9a88_jpg.rf.f08a04590fba92deafdb3def03e97c44.jpg\n",
            "a9987cf6cc5c6545818ec294d4a5bb9b_jpg.rf.95a5bb9f3138fe997ff8faa21a85436f.jpg\n",
            "_annotations.txt\n",
            "b0f3d66c8be13f5f6aa25b67a06bdcfa_jpg.rf.01b3f3243bf31cb2ea18a89fd58044be.jpg\n",
            "b3b002461f1c6b432e22964549767e5f_jpg.rf.46f0298de88abcc93f279274d84d6b6b.jpg\n",
            "b5102d7f9740eee7754ed268becb2163_jpg.rf.d4a8cfe5fa4d0f53d73c64b07ebabbce.jpg\n",
            "b5bcde459ca36f0d1f3c20e751336672_jpg.rf.667ee729363a8d60c926d9dd3734bf2f.jpg\n",
            "b79ae5b70de58089ead6e32b235e30d3_jpg.rf.87a4a8323a2c39c2f925c7987a01d1b6.jpg\n",
            "b7a8c7de4fe1382d69f58ac97e819b5c_jpg.rf.7b795ae14bd822803c9f193def40e3ef.jpg\n",
            "bb54af2f0b83b174aecc29328c8fa001_jpg.rf.3224d475bfa4e44af5b808c58d411c4d.jpg\n",
            "bc5decab88861286dcf78a367b4377cb_jpg.rf.99264d2583f17e6ba8a7b2e15c54271a.jpg\n",
            "beb11566e59775b61f0ca369952067cc_jpg.rf.f2f174dcc0acd5991b822c5ca1a6735a.jpg\n",
            "c0d68e012bb93c14bc333fc1d5e52621_jpg.rf.60fc27683bf9457b110251dbc3bb7c4b.jpg\n",
            "c3e3b51f63d344be346e6e425f30f87a_jpg.rf.f88e789167d309e0381aa2c9d4a6e322.jpg\n",
            "c3e9e81ba1540aae7961a4d8d96600ba_jpg.rf.65c56919cca14d00fbe5d2d44ec569de.jpg\n",
            "c46bf04050a2a9323dfe563e8813602f_jpg.rf.4da1d855a20ec2d0deff03a46d8363c9.jpg\n",
            "c733616ab773817dd1a356dbbdf2ee33_jpg.rf.a3c3194c8e748b8ab26858a2646ba856.jpg\n",
            "c76c79e40bd9839a05237934cfa89ca3_jpg.rf.498d8fcd0acd71952f9d92708b360fac.jpg\n",
            "c7890b749d14d3488066cbdfac4620fd_jpg.rf.3850673b2781e44e1a293fe12a9cde12.jpg\n",
            "ca869123d8a0cbcc6e54f4a445e5a78a_jpg.rf.882d99242b6bdb27680eadd4a5904cb2.jpg\n",
            "cae099fe41d6aa30033d71e433c33c8d_jpg.rf.124529e05c30bf412475f20b8f274f95.jpg\n",
            "ce54969567273b9b8a275812ff56e16c_jpg.rf.59df2edfb1d3ece93a0939c27e2ed384.jpg\n",
            "cf2784fa97151d5316b2961b1e62dc45_jpg.rf.af04872f77bc32d96852b458e1b3597d.jpg\n",
            "_classes.txt\n",
            "d079f4e77b2445abceca7534356db743_jpg.rf.463c6a4e369b2ffc0baaef7ebb4a68a2.jpg\n",
            "d0cc2420bce5b14dfd39e55dc3737e57_jpg.rf.0f1c927870242d0e614bd6e320f9969e.jpg\n",
            "d29148a2233950a7777285281cbfccff_jpg.rf.2e63366f947507e0735a25d532caaa54.jpg\n",
            "d33c33de41dbe1a95a43212c58fd12b7_jpg.rf.fca260fa864f5898d61bee78b5f152e1.jpg\n",
            "d3a4e1b8f13ef89f419251f5c5839d0d_jpg.rf.e4b5ce214ea2670fa96ab949aec57dcc.jpg\n",
            "d415969922564f317be0d1433330626f_jpg.rf.ec44988c2ee838f90f37cc64ea149905.jpg\n",
            "d494cb268ad7f9f55587de138edc1dc4_jpg.rf.a61a3722fe947a9e22034acaaff19a8b.jpg\n",
            "d67b5b9e900409b050dd9bd594f90709_jpg.rf.7559a07ac3b4029a5a287b4b7b96ea37.jpg\n",
            "d795f84f39716798482fb2937868ed8a_jpg.rf.714951561ee3a485ad7bb06fe4377bf5.jpg\n",
            "d9acc69c5d57623cda22786e309201c9_jpg.rf.dc4a82120ade321eeae8146c917e3109.jpg\n",
            "dd6b5c3cb2d7e77f38f1dfeb2bff0431_jpg.rf.065f8833508d101a1f1449e8fbabc314.jpg\n",
            "dda052fc8dbcce6154d6874a663743eb_jpg.rf.5f2765d09b2e90e6a1d5a629a006e6ac.jpg\n",
            "ddad9dc4d945006d66f5349d64498559_jpg.rf.3d6e55223a3ce985572a9e46d7c6a9f8.jpg\n",
            "de60ba81aa78387928e4bdc11f3be301_jpg.rf.e7b8966eca79a6758f9f2eedfcf1177c.jpg\n",
            "e40003d4bbcdac7196b9502bfe2fb6ed_jpg.rf.67e2013fa9dd32e5a94dc926ddabfd35.jpg\n",
            "e4209b257f3706992c059c836cc42ec7_jpg.rf.ed76056e3061801af1c2cdf46bea57fc.jpg\n",
            "e6e3a2ff2c75970490079f00136885ad_jpg.rf.2733f54e2f320fbc9c5e0058c731d765.jpg\n",
            "e79deba8fe520409790b601ad61da4ee_jpg.rf.016bc04dee292f80d1f975931f32bc21.jpg\n",
            "e8480d7fb9881d8a0e88b7be4d103f6d_jpg.rf.2bc6fa7acb94ff9b2993d2de0c7def9e.jpg\n",
            "ea799d77875c399618c45cd9409f34ee_jpg.rf.316738a20243cf9a9a408b56ccaa5616.jpg\n",
            "eb9e7928e756c3cf9164e7afc08c4653_jpg.rf.48f982d13896a1d8c0c7a566cdde2129.jpg\n",
            "ec4c30d88ecc70b6a3e76dbd9b17324a_jpg.rf.da4ab525f8d9b96b4de4067bd6694cbb.jpg\n",
            "ec5ab1930d6aa16fff2582b48f82cada_jpg.rf.ab0666b98c1ed6aed1a7a268fdb79ec6.jpg\n",
            "edd285915356686fb53fb52c1ded0e53_jpg.rf.9e9b27a0d423c4ec63e6e1dd825d8ced.jpg\n",
            "ef1d425fd5370fbf8b7adea43b755304_jpg.rf.509cd10372ad2fe7def2c49881348306.jpg\n",
            "f02d615907c77dc15f02bd1372e4398f_jpg.rf.b46e520760107eb69d290ac810d8e1aa.jpg\n",
            "f041d3171dfe3137390c85fc5437e447_jpg.rf.8814a03f0ba5cf32468d13ff688c5594.jpg\n",
            "f1ea0167087976926d4fe0aa36b961ce_jpg.rf.ab4d245320384c2d04ba6e9ba6a652ec.jpg\n",
            "f2672cdc28767484b556da3ab6f1003e_jpg.rf.7d0badf9505f1655f0561107d11a19f1.jpg\n",
            "f3302c754c6fd42130014199ee327d10_jpg.rf.56672ccf94cd354a96888ca0e8a8e4e0.jpg\n",
            "f3a5df526393445c6e2d38f66c1f5c27_jpg.rf.09aeba93cdea53cc6a6db62f6056ec35.jpg\n",
            "f3e64e9dd12b65b941c142d142b33ef5_jpg.rf.a9db857ababa4d01d03eb09a527d29fc.jpg\n",
            "f5231f940bcf1527ef8bb8e46ac0532b_jpg.rf.5d8200f918b607f7dbc41c8533095e41.jpg\n",
            "f52e1873b8583f8bf4f7ddf6e9649f07_jpg.rf.e9f936cd405597e058a5d399d094078d.jpg\n",
            "f587402be410b424bcbbac06e1dc6162_jpg.rf.7181098acae97a248bfa1d0586a3db69.jpg\n",
            "f9a9a175f26d4b26bca3a5338cc1405e_jpg.rf.378f0d92128b1608bc48d47324f380b4.jpg\n",
            "fa3cf2724c1648a8822b59ac0759475f_jpg.rf.3ad41d095557e6bfb446af5de5553e75.jpg\n",
            "fa4e2b9a8cf58f405f69a56c662834f2_jpg.rf.2ac2e858d136ce51bcecdc1129187214.jpg\n",
            "fb586797e8ad818c7e3e3a6411f73d84_jpg.rf.52352f51cdef2f343756ef296af65d9e.jpg\n",
            "fc9d7bc0453cb3324406401c00224d30_jpg.rf.c596d992843d8a35d80cadf5489e0770.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUWFxHW_mjlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# move everything from the Roboflow export to the root of our keras-yolo3 folder\n",
        "%mv * ../"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "200_8-VImWmK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8e32c29c-e117-4a2d-8cbb-d295f285d0d7"
      },
      "source": [
        "# change directory back to our \n",
        "%cd .."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-yolo3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQASf1hzmxE7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eba46580-36f7-45b5-f8dd-fb40216a83cd"
      },
      "source": [
        "# show that all our images, _annotations.txt, and _classes.txt made it to our root directory\n",
        "%ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00bc0cacffdebe6b11bdeec56f63ee49_jpg.rf.59f0f02a28f020d480fd5d1d8aa32f6d.jpg\n",
            "0115e4df73475b550e5c6f7a88b2474f_jpg.rf.dfa577bd4af5440d689046c2f48bc48e.jpg\n",
            "02f0931b536dfba10affc3231a3d64fb_jpg.rf.7daf233a70122377355a36ca33e82aa4.jpg\n",
            "0301b7f9ed4d5ba503fda79fc4370c29_jpg.rf.3ecfd27607406c9f46c1525efd39e17b.jpg\n",
            "03886821377011fec599e8fa12d86e89_jpg.rf.78d439f975872bc0120d597bd265684b.jpg\n",
            "03d3ff4582c8125d69c19a72f846bec8_jpg.rf.5f77781cbc56eff8679f258ff4f7cc9f.jpg\n",
            "040f2bcba5afce3afafdd5bbf36d2ca5_jpg.rf.fe6d0720247b60f2c6e1cda98fd00cab.jpg\n",
            "04aed88a8d23cf27e47806eb23948495_jpg.rf.4021af803b1b21022221cd3654117580.jpg\n",
            "055b79dd8db4c43e1a23be6095aaf624_jpg.rf.3eddea89d44864ecd7971d2827ee88df.jpg\n",
            "05de676d5078dc0a13796f3f627993ef_jpg.rf.70a6ddff100e5f321d7d6f8d4d977e3d.jpg\n",
            "06770ce99d4866165c0dfb104179c361_jpg.rf.e7acda724f1beddf07e9cc9ee750f3d5.jpg\n",
            "0798bfb058da59d189c1bfadcf814f29_jpg.rf.b73199953251d84e4895a862463b7964.jpg\n",
            "0b4ba28f0c759a11750a6430649b52e3_jpg.rf.c732477a7f65117e3fb24bbd7bca5b8e.jpg\n",
            "0cf670506bf9e0fe587647cd62caa232_jpg.rf.cc43d799dab21abc85a4368295867d8f.jpg\n",
            "0d9dbf62d5ee42b92bf55197bba4254d_jpg.rf.3dfbde3b99d83e88daa3b69514daa68d.jpg\n",
            "0f4512d71c096f2699d705792e88fc58_jpg.rf.0971fe35ffe3ebbcc3e2a709de978aec.jpg\n",
            "104ec0199cb67e1a359b1b0845ee66f3_jpg.rf.2148e2af0737be8e162d7d867805a8ac.jpg\n",
            "13106bbc80a01cc413c2ab5052d2ec25_jpg.rf.6fb6095088bd3962b78e22f736409ea5.jpg\n",
            "1595777dfa66e954ae23655743e24809_jpg.rf.1ce3ed024877808c7e9f12f1f83fefae.jpg\n",
            "1728cd731489df8bb8e0396e178fe393_jpg.rf.9aa607b72daa7a732ab1285f5ff96c66.jpg\n",
            "1877a28e4c5f5c1ea68aca66f4e85d95_jpg.rf.7d7dcb905c94e79222205feb915bafec.jpg\n",
            "196829feb704a34a4e471155f14bdd80_jpg.rf.7b98c9eefcd83f5cf7eea7a95e4ceba3.jpg\n",
            "1a530d578f3f0bf3497bfeff3d953025_jpg.rf.2a30081d7234f714736032af1dcb4193.jpg\n",
            "1a8a4abcba7c4ead35c01f05b9fae8e5_jpg.rf.e36b61dd77198f5d2ffd5c39645638cb.jpg\n",
            "1b4ccdf7d5ff45dc6c3885243bde5af2_jpg.rf.c0b83419aa9e3c1b3b5a9cba2b9ea579.jpg\n",
            "22e74efb18b2d88fba63d25a61bf5f97_jpg.rf.91ebc978b333aae9ba2289e894ff95c3.jpg\n",
            "23988893ef7381fece6d1ef32ef5428f_jpg.rf.5065b0683d241ad92afc074eed391b53.jpg\n",
            "239c409d5c09b493fed01a70a3cda4bc_jpg.rf.f8f5bf822dba445148cf5271f1a7e34d.jpg\n",
            "247f9cf35a263dc7dd7886b187fd5480_jpg.rf.ca7241ecf892e490f69312d56b5a6773.jpg\n",
            "254f92b18b2a81f88b85e7aed3cabc61_jpg.rf.09fc82bf7878065eb6cad223e60f7f0b.jpg\n",
            "26d663ab5ffbec49f9dc8e592982cfd4_jpg.rf.238eb82b4d50cc47759fa7ce82c43b97.jpg\n",
            "285d7c487a4e20ad832a74acb527b77f_jpg.rf.5ce3eb6a89b4c0019fde9d22a5921104.jpg\n",
            "292b0ddcacad7de06a628980954b6993_jpg.rf.3e5a330ebaead704099fbdbcee34d96f.jpg\n",
            "2c32afd520cc8bf076dfa5b6e2e1c4c1_jpg.rf.c546a535eb5f3a68ed59a794c1faeb2a.jpg\n",
            "2ee0fd0963465ba29d8f27c6e605c55d_jpg.rf.b0d9e857c9a56fc8077ea156fca40284.jpg\n",
            "2fe75c34fd54e960146fb8b0ad8b3fd6_jpg.rf.6091e6d4216ef3f71b33d14c30ec0d54.jpg\n",
            "300f80826bbb7dc4bf83e148614f2f77_jpg.rf.d2ebe06b4f53115a03fefa84f8ce7f4e.jpg\n",
            "3057eba7e9b0221ddbdc96a01f39ab79_jpg.rf.f5ca64930fd980c194483c8a3bb6a54e.jpg\n",
            "3091c9b25d76e9cbd0af83ced9f354e5_jpg.rf.d5f14cd80477f444b7ed601f609c67dd.jpg\n",
            "31419854b103ca6becc4cc394c449e95_jpg.rf.ed358e1365d7de3a15257d87752c51b9.jpg\n",
            "3161933dffedf8a859d6623a99492c53_jpg.rf.9267abfc68d9bd6af1912b5d0319f36c.jpg\n",
            "3474d785b1b21d68163f56aa00a92bc9_jpg.rf.7edb79a8e8ad56b74a670a5c43b5cf2a.jpg\n",
            "34ad1966ae7a17d4502ca141413ed8d2_jpg.rf.dd63137d1c9d6095c293b48a0b6f3334.jpg\n",
            "36066ba85572ce99198f1a21c2c8bbff_jpg.rf.1bb4689be2417ff995fbd5e22876c353.jpg\n",
            "3730ef213ac6aad431475a9ab28f349a_jpg.rf.c18235c762e398156f5a67144b46d3a9.jpg\n",
            "3796db002cba7265bd32b0161ddd9127_jpg.rf.4f039ba64a8a26531c2b2861e04cfe7a.jpg\n",
            "37fe05bcf7d8568a9e55b569afdbccbd_jpg.rf.369f4b4dbd105056aa23957cd4be1687.jpg\n",
            "383c2ed7bbe2d327ab55a871db497c33_jpg.rf.ac062d648b1833d4c5ada1dbc6052060.jpg\n",
            "389b4c47568c78c44df11dbb1377ffea_jpg.rf.1d6174519a8e98c853c57584e8cba891.jpg\n",
            "38f26ee82e38d332b2a831aa47bd363b_jpg.rf.ce772b291dcc390ce7786ed11a493495.jpg\n",
            "3914be0cea4aa8a6bbd1081ec3b034a7_jpg.rf.1a22ac976f9598278bbbf963909a32ef.jpg\n",
            "3bab0eaaeb63a2ac9ae4942df4006a25_jpg.rf.a637df4b9da83609e96c1828e1f4366b.jpg\n",
            "3e8fb24addda1a0945bd6b7777bc4018_jpg.rf.d17abcc1ddc47bcc382536d9669e3fd5.jpg\n",
            "446e75de1ffefc2115e79696bcf0e357_jpg.rf.642c290200ecf6bac85bbde223355232.jpg\n",
            "4667110b61b16e786673ed6126ccc35d_jpg.rf.775479ebec16606e8b47874da02463fb.jpg\n",
            "479459fe5c8213a84fd55ba82f2670b1_jpg.rf.c0cbd0b155916350af1e743b11766dfc.jpg\n",
            "47e842dd95735a11cf92c0ddf1161193_jpg.rf.563bd525e9210a59e275a565317b890f.jpg\n",
            "4807629b8df9c7eb4366b7feccd72e6a_jpg.rf.8586b4e2e824f8ee2e108a4a32592c9d.jpg\n",
            "4894f034a55eaa9252cd261a62b11d27_jpg.rf.bb716c1e40a670ecd703683c8dc332c0.jpg\n",
            "48d3c59a99b2b5a5b9f1eb7d5ba63b60_jpg.rf.c196233c6c25ec23958aa743163344b1.jpg\n",
            "48e115dcbf1b3a67ca47a75a92da3f33_jpg.rf.9a3c3e55cb4a229779fc06a672af0765.jpg\n",
            "4939035108d04ee672570a7cc937e270_jpg.rf.a00ea9b7a719681055868d92c1191fe4.jpg\n",
            "49c2afbbe5726160b289f7c0c62cdace_jpg.rf.88443bd77810fdde979f0d6c41bd3cc8.jpg\n",
            "49d365236ee4fb6bd982b0f00bff007e_jpg.rf.16bc32d2b40baeabec00c02b2f9d0e84.jpg\n",
            "49f78dc9aaeadd0c76ed2def75c358f3_jpg.rf.ebe11640761df4735fa11bf2516c7967.jpg\n",
            "4ab3343c9e91e56813f6c36bcac9896a_jpg.rf.959e82a0ff12d5f2276016650905b3d1.jpg\n",
            "4ae38537a74c5ed10d5223f8066659fc_jpg.rf.4fef5c4efc7522714a483c38502f21f2.jpg\n",
            "4bf38c062fa7b5796d15ba90d6c3a456_jpg.rf.47d09ca58c3f5cb00e286ed52ab6f29a.jpg\n",
            "4d6b667ecbd41ebd603b38848366d9d0_jpg.rf.29238774d80d0be8def25571c503714f.jpg\n",
            "4d7820ad9fb4fe69d5168e1d7317dd02_jpg.rf.1279c1ccceab06443a62004f2800d891.jpg\n",
            "4de23afff63bc169b4ebe547a9c9b692_jpg.rf.0cf789652d85886de3d00b05bef061eb.jpg\n",
            "4eb630d4dd38528dacf72355caf5c06d_jpg.rf.cef25bd3e5eb142ccd065e5d26049127.jpg\n",
            "53de0674524ae6d77bdfff48136dec2a_jpg.rf.aadf3edd69993569f90483c91fae1fca.jpg\n",
            "54a90aab8c73562975cc560d51a9d2d1_jpg.rf.f5700e30dc924ed32d1b7e34cff05c04.jpg\n",
            "5758322233deed7ae7adc23536db2a4f_jpg.rf.2ac5b8df5fb0e541557f79cbdd79f51a.jpg\n",
            "57def88c6de500f5f6926354b3680a13_jpg.rf.dd74421d7ddaa3ec1198e12a84a9f1dc.jpg\n",
            "5825608dccde6544eef91822136079d0_jpg.rf.62780259541cb1ed0b071c0594b71147.jpg\n",
            "59727dce26aaa6100078810b61404069_jpg.rf.7c04dbe505cf1bd214e4f491e3a395af.jpg\n",
            "5a8433ec79c881f84ef19a07dc73665d_jpg.rf.8c74727285683022959679af3c43f190.jpg\n",
            "5cecd3b3946aac5c713a51e0bd4617c9_jpg.rf.03286d3792ba33d52a3654e14735c974.jpg\n",
            "5e71cb8d41c333a18e799ef0004b040c_jpg.rf.d65a0847e82174366d01e29a636074e6.jpg\n",
            "614811e933a680fd6535ac8bf06bf530_jpg.rf.0b9ea19fb73269b21cf021c584b84aeb.jpg\n",
            "614aadadb4a7f5b475b027b8e11398ee_jpg.rf.46607639a62cb9241830db1088e145a1.jpg\n",
            "61567b97353acc18ba9e8aac0f111326_jpg.rf.5764028ed4ece48b7894801e884e111e.jpg\n",
            "6179b463c8f503445e213b706d2a4de5_jpg.rf.22c6e0d7cc69bbceddc0ed8a8b0e0bc5.jpg\n",
            "6403b91d63799cb9b5531c47b195d088_jpg.rf.cb883855985dd9bb6c6abc4cbe53fa76.jpg\n",
            "6454bd04e2829d4ff83602f0f2d7154e_jpg.rf.46c9bd543815a1c9758df61f2569524e.jpg\n",
            "6589f4cfb37439d7d276f0d70f7ee1f0_jpg.rf.e6bfa3034bc8005aaadf8ba1aca18e61.jpg\n",
            "65ba27557c78850168b1df70a3ce4ff7_jpg.rf.ef005cf77310609923ff2fb962581194.jpg\n",
            "66f3c2c7c10a9263de9c6e056ba5c1b9_jpg.rf.18efa20b29dfe94acf3cb63ccc92a4b3.jpg\n",
            "673bcd0d44f495fbe9dd88d5cacfceb3_jpg.rf.4f36394a6dc154067ad4da04cf503df8.jpg\n",
            "675619f2c8078824cfd182cec2eeba95_jpg.rf.2a121620701a980a77942a4d8e8a813c.jpg\n",
            "699edbacbfee5e6d4d6d2189bc88990a_jpg.rf.21253a833a9f17c4391a96e64b279fd9.jpg\n",
            "6ba74e310dd824af891d057d674cedb9_jpg.rf.f100b00ae7151f33ca508ed17be6e7c6.jpg\n",
            "6bb6f7cb96bf37230681d12ff7882f61_jpg.rf.b1255adcc94141477b7d089a0b9ebf42.jpg\n",
            "6f0a888f9e5aed9516e336fd04723ce1_jpg.rf.9dbcc89d91a6cada0f389a0e88ecf86b.jpg\n",
            "6f0de9b594de9f9b92c6a20daa51a28a_jpg.rf.e7362c0e232dfa07aa0eb3f52bb4fd50.jpg\n",
            "743665d7ef6ab0330e8786227f6f4051_jpg.rf.6482e654f2b3d8ecebfdaf396c741b07.jpg\n",
            "759a86e63667ca033255c4ab438dd392_jpg.rf.708d1d10d1032312cacd959485e92fa5.jpg\n",
            "76d01bada90581f55f1ae64c062cafcf_jpg.rf.82f338c5d9879e03d2a7455a585493e3.jpg\n",
            "76dbe2ccf986a2a0d399d3d8a47279ad_jpg.rf.582fa23c9cb60c607ce4039d59257eac.jpg\n",
            "76e118acf05a8ebe06957f8882cc06aa_jpg.rf.6170a8b5a9733bae0c02d0ca375bde10.jpg\n",
            "79e744a68d6e6f83be0a9e8761ea66a4_jpg.rf.d796c3ba698ebf673f0d3fc42062e20c.jpg\n",
            "7df16cd59fb40e0691948cc805e4801b_jpg.rf.87b8be301feea11509703396e6f8b8e2.jpg\n",
            "7ee8d13861bdc45e40a7cfe190a8d8a6_jpg.rf.f89633224312e1c80ce73c4e05c65051.jpg\n",
            "80c787b97ed3e2b4befd6b11aa2fba37_jpg.rf.b7e9d028eb34400c5d239b57639e086e.jpg\n",
            "81f5c542ffe0f9eae4df59d29acbcced_jpg.rf.561b8c31b527d84832e277765b20dc4d.jpg\n",
            "859e7157c6d544236a67463c08169b6e_jpg.rf.773fea93fd9593e63fedd9d27f8581a7.jpg\n",
            "8678864272a0a04c4c65ca96324105b4_jpg.rf.23c0e1b2c040efd89095760e27f28eaa.jpg\n",
            "871597c145446cf58c1c2dd7db988864_jpg.rf.dfe014e3493447cc19e30bb97c00239a.jpg\n",
            "889c420fb266b8d0e817306110042bda_jpg.rf.187d72f3d58f732ea576641f5c702f61.jpg\n",
            "8967433350d3b3043902603430fccaab_jpg.rf.b3b6e9ca2da2674266a7d44c368a3953.jpg\n",
            "8bb72e70f0560095885586deba37a524_jpg.rf.addedc80f989194e077b8c53871457b8.jpg\n",
            "8d6f722eadc015a393bd490f9b7a85e6_jpg.rf.651f72c0d06342bd6e79bff0aeea8fd2.jpg\n",
            "8d796de64b9eed1ffd5ebe550d4ca807_jpg.rf.7a9a939f45b77b1804da67fbb088c795.jpg\n",
            "8dd12470c30e3b265e8933a6fee7ad28_jpg.rf.84b8584b870b790d4f5d40bdd24c1af4.jpg\n",
            "8de03901c64a80070048ead3fb0d32bd_jpg.rf.a81d5c2674e7d68b2245ef7725a87fac.jpg\n",
            "8f84f1945fd993facc3368d13345f333_jpg.rf.b190d526f930a1e6e0c8568294cd2837.jpg\n",
            "8ff64b3f770bfe96bdffc629efd16460_jpg.rf.b56392e0638bcb50479d4e74dad8ac8a.jpg\n",
            "9146a6989dac08f1769e677064ebfb49_jpg.rf.adc60b60fd2041dbb3102a4561edf7b6.jpg\n",
            "92992ff9c823e0420bf17e71db9ef4ef_jpg.rf.a9c86b7daee5c7b1977507f760cdd7e8.jpg\n",
            "93557fc861304f7753089c244bc1e33e_jpg.rf.ffbb0460f28c29ea6c2f0e5ff165550c.jpg\n",
            "9504fb6b81031feac1fbf1e128b5c173_jpg.rf.e4e7ce142edc55c73267abbe60ec69b3.jpg\n",
            "969daa72bd7804ea1212e191820249b0_jpg.rf.42fdf983653232bcccbca70f94cbfac4.jpg\n",
            "97aeb1f9b745a929e9ac0848acb53a1a_jpg.rf.5997f0ef95b45103711d4fdc239c2691.jpg\n",
            "9962a4d44388b9008aa0f466e4f4052c_jpg.rf.b2b9e1236e560e47019df29344b0cc10.jpg\n",
            "998222d9c93f1640829d4f0032dbf3e8_jpg.rf.dfdbeef166796c8f4327b3a456ca1cfe.jpg\n",
            "99ee6574b2a7afc0bb06269bbcf49a4c_jpg.rf.693e8999d9c962ab16c457b2225359f0.jpg\n",
            "9a6b61a6d3b3e3ecddc201b097aa02d1_jpg.rf.3903667901a40aedda2c42c43502d96b.jpg\n",
            "9c153a9c9798dab948d4260eb109b315_jpg.rf.04a431391f78af71e5ebaf9d51d91faf.jpg\n",
            "9c5fb0c3cfd7b334a247cd87c139e8e6_jpg.rf.e515316111e554f86ea49e12faeda7a4.jpg\n",
            "9d776e74e90c4f8092b060dd7567e2f8_jpg.rf.5d6deb8a1e7a40c616186a7b90f48c2b.jpg\n",
            "9e943906fba1ec89edfacb2dd7976504_jpg.rf.9702132e48df03814384024ca7313212.jpg\n",
            "9fc54a45feb5b01db8f6828d181fb075_jpg.rf.c78f29bbe2df51ae862c73f5cca0eebd.jpg\n",
            "a20eb4bb3cea2e394cfcf9ed969b628e_jpg.rf.abd0f3c626fca3ba6c4111d4fbf656ab.jpg\n",
            "a4028b2361ce7ead654a86b07ac39d52_jpg.rf.4300592f959cf20135ac198003615490.jpg\n",
            "a4ebf4c268d80c4fe329331ea981b3a1_jpg.rf.a15a2e6dfb1ce2864f46f69bb0c54795.jpg\n",
            "a5c65b40e0be3480c0ecfacaab399a87_jpg.rf.65826955144870ecaf37db65ef6532ae.jpg\n",
            "a8847f8fe8eaaa1c97bf83027a901760_jpg.rf.26afc5ee5c983fe73c8e113e99127fa9.jpg\n",
            "a932287da44b9dfacd0d16a5c1d27923_jpg.rf.5d4b7b1e6f3b0033a85c6fa52a0dbeef.jpg\n",
            "a9768de3fceeeae2618f362870fb9a88_jpg.rf.f08a04590fba92deafdb3def03e97c44.jpg\n",
            "a9987cf6cc5c6545818ec294d4a5bb9b_jpg.rf.95a5bb9f3138fe997ff8faa21a85436f.jpg\n",
            "_annotations.txt\n",
            "b0f3d66c8be13f5f6aa25b67a06bdcfa_jpg.rf.01b3f3243bf31cb2ea18a89fd58044be.jpg\n",
            "b3b002461f1c6b432e22964549767e5f_jpg.rf.46f0298de88abcc93f279274d84d6b6b.jpg\n",
            "b5102d7f9740eee7754ed268becb2163_jpg.rf.d4a8cfe5fa4d0f53d73c64b07ebabbce.jpg\n",
            "b5bcde459ca36f0d1f3c20e751336672_jpg.rf.667ee729363a8d60c926d9dd3734bf2f.jpg\n",
            "b79ae5b70de58089ead6e32b235e30d3_jpg.rf.87a4a8323a2c39c2f925c7987a01d1b6.jpg\n",
            "b7a8c7de4fe1382d69f58ac97e819b5c_jpg.rf.7b795ae14bd822803c9f193def40e3ef.jpg\n",
            "bb54af2f0b83b174aecc29328c8fa001_jpg.rf.3224d475bfa4e44af5b808c58d411c4d.jpg\n",
            "bc5decab88861286dcf78a367b4377cb_jpg.rf.99264d2583f17e6ba8a7b2e15c54271a.jpg\n",
            "beb11566e59775b61f0ca369952067cc_jpg.rf.f2f174dcc0acd5991b822c5ca1a6735a.jpg\n",
            "c0d68e012bb93c14bc333fc1d5e52621_jpg.rf.60fc27683bf9457b110251dbc3bb7c4b.jpg\n",
            "c3e3b51f63d344be346e6e425f30f87a_jpg.rf.f88e789167d309e0381aa2c9d4a6e322.jpg\n",
            "c3e9e81ba1540aae7961a4d8d96600ba_jpg.rf.65c56919cca14d00fbe5d2d44ec569de.jpg\n",
            "c46bf04050a2a9323dfe563e8813602f_jpg.rf.4da1d855a20ec2d0deff03a46d8363c9.jpg\n",
            "c733616ab773817dd1a356dbbdf2ee33_jpg.rf.a3c3194c8e748b8ab26858a2646ba856.jpg\n",
            "c76c79e40bd9839a05237934cfa89ca3_jpg.rf.498d8fcd0acd71952f9d92708b360fac.jpg\n",
            "c7890b749d14d3488066cbdfac4620fd_jpg.rf.3850673b2781e44e1a293fe12a9cde12.jpg\n",
            "ca869123d8a0cbcc6e54f4a445e5a78a_jpg.rf.882d99242b6bdb27680eadd4a5904cb2.jpg\n",
            "cae099fe41d6aa30033d71e433c33c8d_jpg.rf.124529e05c30bf412475f20b8f274f95.jpg\n",
            "ce54969567273b9b8a275812ff56e16c_jpg.rf.59df2edfb1d3ece93a0939c27e2ed384.jpg\n",
            "cf2784fa97151d5316b2961b1e62dc45_jpg.rf.af04872f77bc32d96852b458e1b3597d.jpg\n",
            "_classes.txt\n",
            "coco_annotation.py\n",
            "convert.py\n",
            "d079f4e77b2445abceca7534356db743_jpg.rf.463c6a4e369b2ffc0baaef7ebb4a68a2.jpg\n",
            "d0cc2420bce5b14dfd39e55dc3737e57_jpg.rf.0f1c927870242d0e614bd6e320f9969e.jpg\n",
            "d29148a2233950a7777285281cbfccff_jpg.rf.2e63366f947507e0735a25d532caaa54.jpg\n",
            "d33c33de41dbe1a95a43212c58fd12b7_jpg.rf.fca260fa864f5898d61bee78b5f152e1.jpg\n",
            "d3a4e1b8f13ef89f419251f5c5839d0d_jpg.rf.e4b5ce214ea2670fa96ab949aec57dcc.jpg\n",
            "d415969922564f317be0d1433330626f_jpg.rf.ec44988c2ee838f90f37cc64ea149905.jpg\n",
            "d494cb268ad7f9f55587de138edc1dc4_jpg.rf.a61a3722fe947a9e22034acaaff19a8b.jpg\n",
            "d67b5b9e900409b050dd9bd594f90709_jpg.rf.7559a07ac3b4029a5a287b4b7b96ea37.jpg\n",
            "d795f84f39716798482fb2937868ed8a_jpg.rf.714951561ee3a485ad7bb06fe4377bf5.jpg\n",
            "d9acc69c5d57623cda22786e309201c9_jpg.rf.dc4a82120ade321eeae8146c917e3109.jpg\n",
            "darknet53.cfg\n",
            "dd6b5c3cb2d7e77f38f1dfeb2bff0431_jpg.rf.065f8833508d101a1f1449e8fbabc314.jpg\n",
            "dda052fc8dbcce6154d6874a663743eb_jpg.rf.5f2765d09b2e90e6a1d5a629a006e6ac.jpg\n",
            "ddad9dc4d945006d66f5349d64498559_jpg.rf.3d6e55223a3ce985572a9e46d7c6a9f8.jpg\n",
            "de60ba81aa78387928e4bdc11f3be301_jpg.rf.e7b8966eca79a6758f9f2eedfcf1177c.jpg\n",
            "e40003d4bbcdac7196b9502bfe2fb6ed_jpg.rf.67e2013fa9dd32e5a94dc926ddabfd35.jpg\n",
            "e4209b257f3706992c059c836cc42ec7_jpg.rf.ed76056e3061801af1c2cdf46bea57fc.jpg\n",
            "e6e3a2ff2c75970490079f00136885ad_jpg.rf.2733f54e2f320fbc9c5e0058c731d765.jpg\n",
            "e79deba8fe520409790b601ad61da4ee_jpg.rf.016bc04dee292f80d1f975931f32bc21.jpg\n",
            "e8480d7fb9881d8a0e88b7be4d103f6d_jpg.rf.2bc6fa7acb94ff9b2993d2de0c7def9e.jpg\n",
            "ea799d77875c399618c45cd9409f34ee_jpg.rf.316738a20243cf9a9a408b56ccaa5616.jpg\n",
            "eb9e7928e756c3cf9164e7afc08c4653_jpg.rf.48f982d13896a1d8c0c7a566cdde2129.jpg\n",
            "ec4c30d88ecc70b6a3e76dbd9b17324a_jpg.rf.da4ab525f8d9b96b4de4067bd6694cbb.jpg\n",
            "ec5ab1930d6aa16fff2582b48f82cada_jpg.rf.ab0666b98c1ed6aed1a7a268fdb79ec6.jpg\n",
            "edd285915356686fb53fb52c1ded0e53_jpg.rf.9e9b27a0d423c4ec63e6e1dd825d8ced.jpg\n",
            "ef1d425fd5370fbf8b7adea43b755304_jpg.rf.509cd10372ad2fe7def2c49881348306.jpg\n",
            "f02d615907c77dc15f02bd1372e4398f_jpg.rf.b46e520760107eb69d290ac810d8e1aa.jpg\n",
            "f041d3171dfe3137390c85fc5437e447_jpg.rf.8814a03f0ba5cf32468d13ff688c5594.jpg\n",
            "f1ea0167087976926d4fe0aa36b961ce_jpg.rf.ab4d245320384c2d04ba6e9ba6a652ec.jpg\n",
            "f2672cdc28767484b556da3ab6f1003e_jpg.rf.7d0badf9505f1655f0561107d11a19f1.jpg\n",
            "f3302c754c6fd42130014199ee327d10_jpg.rf.56672ccf94cd354a96888ca0e8a8e4e0.jpg\n",
            "f3a5df526393445c6e2d38f66c1f5c27_jpg.rf.09aeba93cdea53cc6a6db62f6056ec35.jpg\n",
            "f3e64e9dd12b65b941c142d142b33ef5_jpg.rf.a9db857ababa4d01d03eb09a527d29fc.jpg\n",
            "f5231f940bcf1527ef8bb8e46ac0532b_jpg.rf.5d8200f918b607f7dbc41c8533095e41.jpg\n",
            "f52e1873b8583f8bf4f7ddf6e9649f07_jpg.rf.e9f936cd405597e058a5d399d094078d.jpg\n",
            "f587402be410b424bcbbac06e1dc6162_jpg.rf.7181098acae97a248bfa1d0586a3db69.jpg\n",
            "f9a9a175f26d4b26bca3a5338cc1405e_jpg.rf.378f0d92128b1608bc48d47324f380b4.jpg\n",
            "fa3cf2724c1648a8822b59ac0759475f_jpg.rf.3ad41d095557e6bfb446af5de5553e75.jpg\n",
            "fa4e2b9a8cf58f405f69a56c662834f2_jpg.rf.2ac2e858d136ce51bcecdc1129187214.jpg\n",
            "fb586797e8ad818c7e3e3a6411f73d84_jpg.rf.52352f51cdef2f343756ef296af65d9e.jpg\n",
            "fc9d7bc0453cb3324406401c00224d30_jpg.rf.c596d992843d8a35d80cadf5489e0770.jpg\n",
            "\u001b[0m\u001b[01;34mfont\u001b[0m/\n",
            "kmeans.py\n",
            "LICENSE\n",
            "\u001b[01;34mmodel_data\u001b[0m/\n",
            "README.dataset.txt\n",
            "README.md\n",
            "README.roboflow.txt\n",
            "\u001b[01;34mtest\u001b[0m/\n",
            "\u001b[01;34mtrain\u001b[0m/\n",
            "train_bottleneck.py\n",
            "train.py\n",
            "Tutorial.ipynb\n",
            "\u001b[01;34mvalid\u001b[0m/\n",
            "voc_annotation.py\n",
            "\u001b[01;34myolo3\u001b[0m/\n",
            "yolo.py\n",
            "yolov3.cfg\n",
            "yolov3-tiny.cfg\n",
            "yolo_video.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvzqgP92W7bt",
        "colab_type": "text"
      },
      "source": [
        "## Set up and train our model\n",
        "\n",
        "Next, we'll download pre-trained weighs weights from DarkNet, set up our YOLOv3 architecture with those pre-trained weights, and initiate training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJzW08g2VlwD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "f573d3c2-34e3-43e5-8aaf-86f289091788"
      },
      "source": [
        "# download our DarkNet weights \n",
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-07 18:27:22--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: â€˜yolov3.weightsâ€™\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M   461KB/s    in 9m 49s  \n",
            "\n",
            "2020-08-07 18:37:12 (411 KB/s) - â€˜yolov3.weightsâ€™ saved [248007048/248007048]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mub8GJMBVluA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "53d361fe-268b-4bde-930b-eb9022265896"
      },
      "source": [
        "# call a Python script to set up our architecture with downloaded pre-trained weights\n",
        "!python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Loading weights.\n",
            "Weights Header:  0 2 0 [32013312]\n",
            "Parsing Darknet config.\n",
            "Creating Keras model.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "Parsing section net_0\n",
            "Parsing section convolutional_0\n",
            "conv2d bn leaky (3, 3, 3, 32)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2020-08-07 18:43:58.160532: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-08-07 18:43:58.163465: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-08-07 18:43:58.163632: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x161aa00 executing computations on platform Host. Devices:\n",
            "2020-08-07 18:43:58.163659: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2020-08-07 18:43:58.172315: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "Parsing section convolutional_1\n",
            "conv2d bn leaky (3, 3, 32, 64)\n",
            "Parsing section convolutional_2\n",
            "conv2d bn leaky (1, 1, 64, 32)\n",
            "Parsing section convolutional_3\n",
            "conv2d bn leaky (3, 3, 32, 64)\n",
            "Parsing section shortcut_0\n",
            "Parsing section convolutional_4\n",
            "conv2d bn leaky (3, 3, 64, 128)\n",
            "Parsing section convolutional_5\n",
            "conv2d bn leaky (1, 1, 128, 64)\n",
            "Parsing section convolutional_6\n",
            "conv2d bn leaky (3, 3, 64, 128)\n",
            "Parsing section shortcut_1\n",
            "Parsing section convolutional_7\n",
            "conv2d bn leaky (1, 1, 128, 64)\n",
            "Parsing section convolutional_8\n",
            "conv2d bn leaky (3, 3, 64, 128)\n",
            "Parsing section shortcut_2\n",
            "Parsing section convolutional_9\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section convolutional_10\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_11\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_3\n",
            "Parsing section convolutional_12\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_13\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_4\n",
            "Parsing section convolutional_14\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_15\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_5\n",
            "Parsing section convolutional_16\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_17\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_6\n",
            "Parsing section convolutional_18\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_19\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_7\n",
            "Parsing section convolutional_20\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_21\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_8\n",
            "Parsing section convolutional_22\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_23\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_9\n",
            "Parsing section convolutional_24\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_25\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_10\n",
            "Parsing section convolutional_26\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_27\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_28\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_11\n",
            "Parsing section convolutional_29\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_30\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_12\n",
            "Parsing section convolutional_31\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_32\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_13\n",
            "Parsing section convolutional_33\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_34\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_14\n",
            "Parsing section convolutional_35\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_36\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_15\n",
            "Parsing section convolutional_37\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_38\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_16\n",
            "Parsing section convolutional_39\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_40\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_17\n",
            "Parsing section convolutional_41\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_42\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_18\n",
            "Parsing section convolutional_43\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_44\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_45\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_19\n",
            "Parsing section convolutional_46\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_47\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_20\n",
            "Parsing section convolutional_48\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_49\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_21\n",
            "Parsing section convolutional_50\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_51\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_22\n",
            "Parsing section convolutional_52\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_53\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_54\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_55\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_56\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_57\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_58\n",
            "conv2d    linear (1, 1, 1024, 255)\n",
            "Parsing section yolo_0\n",
            "Parsing section route_0\n",
            "Parsing section convolutional_59\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section upsample_0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "Parsing section route_1\n",
            "Concatenating route layers: [<tf.Tensor 'up_sampling2d_1/ResizeNearestNeighbor:0' shape=(?, ?, ?, 256) dtype=float32>, <tf.Tensor 'add_19/add:0' shape=(?, ?, ?, 512) dtype=float32>]\n",
            "Parsing section convolutional_60\n",
            "conv2d bn leaky (1, 1, 768, 256)\n",
            "Parsing section convolutional_61\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_62\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_63\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_64\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_65\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_66\n",
            "conv2d    linear (1, 1, 512, 255)\n",
            "Parsing section yolo_1\n",
            "Parsing section route_2\n",
            "Parsing section convolutional_67\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section upsample_1\n",
            "Parsing section route_3\n",
            "Concatenating route layers: [<tf.Tensor 'up_sampling2d_2/ResizeNearestNeighbor:0' shape=(?, ?, ?, 128) dtype=float32>, <tf.Tensor 'add_11/add:0' shape=(?, ?, ?, 256) dtype=float32>]\n",
            "Parsing section convolutional_68\n",
            "conv2d bn leaky (1, 1, 384, 128)\n",
            "Parsing section convolutional_69\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section convolutional_70\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_71\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section convolutional_72\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_73\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section convolutional_74\n",
            "conv2d    linear (1, 1, 256, 255)\n",
            "Parsing section yolo_2\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, None, 3 128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, None, None, 3 0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 6 18432       zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, None, None, 6 256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 3 2048        leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, None, 3 128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, None, None, 6 18432       leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, None, None, 6 256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 6 0           leaky_re_lu_2[0][0]              \n",
            "                                                                 leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, None, None, 6 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, None, None, 1 73728       zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, None, None, 1 512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, None, None, 6 8192        leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, None, None, 6 256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, None, None, 1 512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 1 0           leaky_re_lu_5[0][0]              \n",
            "                                                                 leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, None, None, 6 8192        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, None, None, 6 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, None, None, 1 512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 1 0           add_2[0][0]                      \n",
            "                                                                 leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, None, None, 1 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, None, None, 2 294912      zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, None, None, 2 1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, None, None, 1 512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, None, None, 2 1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 2 0           leaky_re_lu_10[0][0]             \n",
            "                                                                 leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, None, None, 1 32768       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, None, None, 1 512         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, None, None, 2 1024        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 2 0           add_4[0][0]                      \n",
            "                                                                 leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, None, None, 1 32768       add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, None, None, 1 512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, None, None, 2 1024        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 2 0           add_5[0][0]                      \n",
            "                                                                 leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, None, None, 1 32768       add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, None, None, 1 512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, None, None, 2 1024        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 2 0           add_6[0][0]                      \n",
            "                                                                 leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, None, None, 1 32768       add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, None, None, 1 512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, None, None, 2 1024        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, None, None, 2 0           add_7[0][0]                      \n",
            "                                                                 leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, None, None, 1 32768       add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, None, None, 1 512         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, None, None, 2 1024        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, None, None, 2 0           add_8[0][0]                      \n",
            "                                                                 leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, None, None, 1 32768       add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, None, None, 1 512         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, None, None, 2 1024        conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, None, None, 2 0           add_9[0][0]                      \n",
            "                                                                 leaky_re_lu_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, None, None, 1 32768       add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, None, None, 1 512         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, None, None, 2 1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, None, None, 2 0           add_10[0][0]                     \n",
            "                                                                 leaky_re_lu_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, None, None, 2 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, None, None, 5 1179648     zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, None, None, 5 2048        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, None, None, 2 1024        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, None, None, 5 2048        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, None, None, 5 0           leaky_re_lu_27[0][0]             \n",
            "                                                                 leaky_re_lu_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, None, None, 2 131072      add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, None, None, 2 1024        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, None, None, 5 2048        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, None, None, 5 0           add_12[0][0]                     \n",
            "                                                                 leaky_re_lu_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, None, None, 2 131072      add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, None, None, 2 1024        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, None, None, 5 2048        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, None, None, 5 0           add_13[0][0]                     \n",
            "                                                                 leaky_re_lu_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, None, None, 2 131072      add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, None, None, 2 1024        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_34 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, None, None, 5 2048        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_35 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, None, None, 5 0           add_14[0][0]                     \n",
            "                                                                 leaky_re_lu_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, None, None, 2 131072      add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, None, None, 2 1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_36 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, None, None, 5 2048        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_37 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, None, None, 5 0           add_15[0][0]                     \n",
            "                                                                 leaky_re_lu_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, None, None, 2 131072      add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, None, None, 2 1024        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_38 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, None, None, 5 2048        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_39 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, None, None, 5 0           add_16[0][0]                     \n",
            "                                                                 leaky_re_lu_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, None, None, 2 131072      add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, None, None, 2 1024        conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_40 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, None, None, 5 2048        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_41 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, None, None, 5 0           add_17[0][0]                     \n",
            "                                                                 leaky_re_lu_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, None, None, 2 131072      add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, None, None, 2 1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_42 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, None, None, 5 2048        conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_43 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, None, None, 5 0           add_18[0][0]                     \n",
            "                                                                 leaky_re_lu_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, None, None, 5 0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, None, None, 1 4718592     zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, None, None, 1 4096        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_44 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, None, None, 5 2048        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_45 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, None, None, 1 4096        conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_46 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, None, None, 1 0           leaky_re_lu_44[0][0]             \n",
            "                                                                 leaky_re_lu_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, None, None, 5 524288      add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, None, None, 5 2048        conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_47 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, None, None, 1 4096        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_48 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, None, None, 1 0           add_20[0][0]                     \n",
            "                                                                 leaky_re_lu_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, None, None, 5 524288      add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, None, None, 5 2048        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_49 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, None, None, 1 4096        conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_50 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, None, None, 1 0           add_21[0][0]                     \n",
            "                                                                 leaky_re_lu_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, None, None, 5 524288      add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, None, None, 5 2048        conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_51 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, None, None, 1 4096        conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_52 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, None, None, 1 0           add_22[0][0]                     \n",
            "                                                                 leaky_re_lu_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, None, None, 5 524288      add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, None, None, 5 2048        conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_53 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, None, None, 1 4096        conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_54 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, None, None, 5 2048        conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_55 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, None, None, 1 4096        conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_56 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, None, None, 5 2048        conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_57 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, None, None, 2 1024        conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_59 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, None, None, 2 0           leaky_re_lu_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, None, 7 0           up_sampling2d_1[0][0]            \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, None, None, 2 196608      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, None, None, 2 1024        conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_60 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, None, None, 5 2048        conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_61 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, None, None, 2 1024        conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_62 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, None, None, 5 2048        conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_63 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, None, None, 2 1024        conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_64 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, None, None, 1 512         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_66 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, None, None, 1 0           leaky_re_lu_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, None, None, 3 0           up_sampling2d_2[0][0]            \n",
            "                                                                 add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, None, None, 1 49152       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, None, None, 1 512         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_67 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, None, None, 2 1024        conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_68 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, None, None, 1 512         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_69 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_69[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, None, None, 2 1024        conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_70 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_70[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, None, None, 1 512         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_71 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, None, None, 1 4096        conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, None, None, 5 2048        conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, None, None, 2 1024        conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_58 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_65 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_72 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, None, None, 2 261375      leaky_re_lu_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, None, None, 2 130815      leaky_re_lu_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, None, None, 2 65535       leaky_re_lu_72[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 62,001,757\n",
            "Trainable params: 61,949,149\n",
            "Non-trainable params: 52,608\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Saved Keras model to model_data/yolo.h5\n",
            "Read 62001757 of 62001757.0 from Darknet weights.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt7MzR_OOHW9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1fa133ab-54d8-4aaa-f6b1-6ee8c1e66127"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLTDkS3POirX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "tf.python.control_flow_ops = tf "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF7b3dlumFGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "4c630413-85b5-41ce-dde8-35551827598d"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5fe4fe9b0c7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEDHwJ36YyXA",
        "colab_type": "text"
      },
      "source": [
        "Below, we'll call a \"self-contained\" Python script that initiates training our model on our custom dataset.\n",
        "\n",
        "Pay notable attention to:\n",
        "- setting the paths for our `annotation_path`, `classes_path`, `class_names`. If you move the Roboflow data location, you'll need to update these. \n",
        "- `val_split` dictates the size of our training data relative to our taining data\n",
        "- `lr=1e-3` to set the learning rate of the model. Smaller optimizes more slowly but potentially more precisely.\n",
        "- `batch_size` for the number of images trained per batch\n",
        "-  `epoch` inside `model.fit_generator()` sets the number training epochs to increase/decrease training examples (and time)\n",
        "\n",
        "Consider reading the YOLOv3 paper [here](https://pjreddie.com/media/files/papers/YOLOv3.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hBFndz8VeI6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19ed1762-8c37-4724-821d-2d80d1b7da60"
      },
      "source": [
        "\"\"\"\n",
        "Self-contained Python script to train YOLOv3 on your own dataset\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.layers import Input, Lambda\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
        "from yolo3.utils import get_random_data\n",
        "\n",
        "\n",
        "def _main():\n",
        "    annotation_path = '_annotations.txt'  # path to Roboflow data annotations\n",
        "    log_dir = 'logs/000/'                 # where we're storing our logs\n",
        "    classes_path = '_classes.txt'         # path to Roboflow class names\n",
        "    anchors_path = 'model_data/yolo_anchors.txt'\n",
        "    class_names = get_classes(classes_path)\n",
        "    print(\"-------------------CLASS NAMES-------------------\")\n",
        "    print(class_names)\n",
        "    print(\"-------------------CLASS NAMES-------------------\")\n",
        "    num_classes = len(class_names)\n",
        "    anchors = get_anchors(anchors_path)\n",
        "\n",
        "    input_shape = (416,416) # multiple of 32, hw\n",
        "\n",
        "    is_tiny_version = len(anchors)==6 # default setting\n",
        "    if is_tiny_version:\n",
        "        model = create_tiny_model(input_shape, anchors, num_classes,\n",
        "            freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n",
        "    else:\n",
        "        model = create_model(input_shape, anchors, num_classes,\n",
        "            freeze_body=2, weights_path='model_data/yolo.h5') # make sure you know what you freeze\n",
        "\n",
        "    logging = TensorBoard(log_dir=log_dir)\n",
        "    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
        "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
        "\n",
        "    val_split = 0.2 # set the size of the validation set\n",
        "    with open(annotation_path) as f:\n",
        "        lines = f.readlines()\n",
        "    np.random.seed(10101)\n",
        "    np.random.shuffle(lines)\n",
        "    np.random.seed(None)\n",
        "    num_val = int(len(lines)*val_split)\n",
        "    num_train = len(lines) - num_val\n",
        "\n",
        "    # Train with frozen layers first, to get a stable loss.\n",
        "    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
        "    if True:\n",
        "        model.compile(optimizer=Adam(lr=1e-3), loss={\n",
        "            # use custom yolo_loss Lambda layer.\n",
        "            'yolo_loss': lambda y_true, y_pred: y_pred})\n",
        "\n",
        "        batch_size = 32\n",
        "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "                steps_per_epoch=max(1, num_train//batch_size),\n",
        "                validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "                validation_steps=max(1, num_val//batch_size),\n",
        "                epochs=500,\n",
        "                initial_epoch=0,\n",
        "                callbacks=[logging, checkpoint])\n",
        "        model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
        "\n",
        "    # Unfreeze and continue training, to fine-tune.\n",
        "    # Train longer if the result is not good.\n",
        "    if True:\n",
        "        for i in range(len(model.layers)):\n",
        "            model.layers[i].trainable = True\n",
        "        model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
        "        print('Unfreeze all of the layers.')\n",
        "\n",
        "        batch_size = 32 # note that more GPU memory is required after unfreezing the body\n",
        "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "            steps_per_epoch=max(1, num_train//batch_size),\n",
        "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "            validation_steps=max(1, num_val//batch_size),\n",
        "            epochs=100,\n",
        "            initial_epoch=50,\n",
        "            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
        "        model.save_weights(log_dir + 'trained_weights_final.h5')\n",
        "\n",
        "    # Further training if needed.\n",
        "\n",
        "\n",
        "def get_classes(classes_path):\n",
        "    '''loads the classes'''\n",
        "    with open(classes_path) as f:\n",
        "        class_names = f.readlines()\n",
        "    class_names = [c.strip() for c in class_names]\n",
        "    return class_names\n",
        "\n",
        "def get_anchors(anchors_path):\n",
        "    '''loads the anchors from a file'''\n",
        "    with open(anchors_path) as f:\n",
        "        anchors = f.readline()\n",
        "    anchors = [float(x) for x in anchors.split(',')]\n",
        "    return np.array(anchors).reshape(-1, 2)\n",
        "\n",
        "\n",
        "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
        "            weights_path='model_data/yolo.h5'):\n",
        "    '''create the training model'''\n",
        "    K.clear_session() # get a new session\n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
        "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
        "\n",
        "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
        "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
        "\n",
        "    if load_pretrained:\n",
        "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "        print('Load weights {}.'.format(weights_path))\n",
        "        if freeze_body in [1, 2]:\n",
        "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
        "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
        "            for i in range(num): model_body.layers[i].trainable = False\n",
        "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        "\n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
        "        [*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
        "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
        "    '''create the training model, for Tiny YOLOv3'''\n",
        "    K.clear_session() # get a new session\n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
        "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
        "\n",
        "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
        "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
        "\n",
        "    if load_pretrained:\n",
        "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "        print('Load weights {}.'.format(weights_path))\n",
        "        if freeze_body in [1, 2]:\n",
        "            # Freeze the darknet body or freeze all but 2 output layers.\n",
        "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
        "            for i in range(num): model_body.layers[i].trainable = False\n",
        "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        "\n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
        "        [*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        "\n",
        "    return model\n",
        "\n",
        "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    '''data generator for fit_generator'''\n",
        "    n = len(annotation_lines)\n",
        "    i = 0\n",
        "    while True:\n",
        "        image_data = []\n",
        "        box_data = []\n",
        "        for b in range(batch_size):\n",
        "            if i==0:\n",
        "                np.random.shuffle(annotation_lines)\n",
        "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
        "            image_data.append(image)\n",
        "            box_data.append(box)\n",
        "            i = (i+1) % n\n",
        "        image_data = np.array(image_data)\n",
        "        box_data = np.array(box_data)\n",
        "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
        "        yield [image_data, *y_true], np.zeros(batch_size)\n",
        "\n",
        "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    n = len(annotation_lines)\n",
        "    if n==0 or batch_size<=0: return None\n",
        "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    _main()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------CLASS NAMES-------------------\n",
            "['black-bishop', 'black-king', 'black-knight', 'black-pawn', 'black-queen', 'black-rook', 'white-bishop', 'white-king', 'white-knight', 'white-pawn', 'white-queen', 'white-rook']\n",
            "-------------------CLASS NAMES-------------------\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "Create YOLOv3 model with 9 anchors and 12 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((1, 1, 1024, 51) vs (255, 1024, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((51,) vs (255,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((1, 1, 512, 51) vs (255, 512, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((51,) vs (255,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((1, 1, 256, 51) vs (255, 256, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((51,) vs (255,)).\n",
            "  weight_values[i].shape))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Load weights model_data/yolo.h5.\n",
            "Freeze the first 249 layers of total 252 layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3080: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Train on 162 samples, val on 40 samples, with batch size 32.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/500\n",
            "5/5 [==============================] - 273s 55s/step - loss: 9231.2955 - val_loss: 6253.0322\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 240s 48s/step - loss: 5460.7527 - val_loss: 3410.9690\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 241s 48s/step - loss: 3182.6054 - val_loss: 2055.4807\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 241s 48s/step - loss: 1931.4887 - val_loss: 1202.5059\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 242s 48s/step - loss: 1210.8057 - val_loss: 776.1859\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 237s 47s/step - loss: 872.1165 - val_loss: 552.8497\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 237s 47s/step - loss: 658.4969 - val_loss: 458.2141\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 238s 48s/step - loss: 517.8004 - val_loss: 372.3161\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 236s 47s/step - loss: 461.7096 - val_loss: 323.7812\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 236s 47s/step - loss: 402.2885 - val_loss: 298.7763\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 236s 47s/step - loss: 352.9560 - val_loss: 275.6048\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 237s 47s/step - loss: 333.9374 - val_loss: 235.7642\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 244s 49s/step - loss: 316.3402 - val_loss: 242.3736\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 243s 49s/step - loss: 296.3605 - val_loss: 219.9873\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 240s 48s/step - loss: 285.2022 - val_loss: 203.3132\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 243s 49s/step - loss: 271.6181 - val_loss: 210.2897\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 240s 48s/step - loss: 248.7976 - val_loss: 172.8401\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 236s 47s/step - loss: 247.9186 - val_loss: 202.9122\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 235s 47s/step - loss: 224.6673 - val_loss: 180.3419\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 236s 47s/step - loss: 235.8105 - val_loss: 174.2049\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 237s 47s/step - loss: 209.5685 - val_loss: 172.3974\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 238s 48s/step - loss: 204.8581 - val_loss: 173.8162\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 235s 47s/step - loss: 212.8727 - val_loss: 149.6888\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 234s 47s/step - loss: 182.6471 - val_loss: 144.4793\n",
            "Epoch 25/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-fd737c45ef07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0m_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-fd737c45ef07>\u001b[0m in \u001b[0;36m_main\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 callbacks=[logging, checkpoint])\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'trained_weights_stage_1.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48yw4UaOYgQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## can call this cell instead of the above\n",
        "# !python train.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFX-2_M8bMQ3",
        "colab_type": "text"
      },
      "source": [
        "## Use our model for inference\n",
        "\n",
        "For predictions, we'll call a a Python script called `yolo_video.py` with required arguments for our use case: a path to our specific first stage trained weights (see our blog for why we're using only stage one), a path to our custom class names, and a flag to specify we're using images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlVyevd8b8gG",
        "colab_type": "text"
      },
      "source": [
        "Additional arguments for `yolo_video.py` are as follows:\n",
        "\n",
        "```\n",
        "usage: yolo_video.py [-h] [--model MODEL] [--anchors ANCHORS]\n",
        "                     [--classes CLASSES] [--gpu_num GPU_NUM] [--image]\n",
        "                     [--input] [--output]\n",
        "\n",
        "positional arguments:\n",
        "  --input        Video input path\n",
        "  --output       Video output path\n",
        "\n",
        "optional arguments:\n",
        "  -h, --help         show this help message and exit\n",
        "  --model MODEL      path to model weight file, default model_data/yolo.h5\n",
        "  --anchors ANCHORS  path to anchor definitions, default\n",
        "                     model_data/yolo_anchors.txt\n",
        "  --classes CLASSES  path to class definitions, default\n",
        "                     model_data/coco_classes.txt\n",
        "  --gpu_num GPU_NUM  Number of GPU to use, default 1\n",
        "  --image            Image detection mode, will ignore all positional arguments\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcJbmgNEO1bE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python yolo_video.py --model=\"./logs/000/trained_weights_stage_1.h5\" --classes=\"_classes.txt\" --image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbACT_RJdGVg",
        "colab_type": "text"
      },
      "source": [
        "For input image names into the above, consider trying the following:\n",
        "\n",
        "- `00a7a49c47d51fd16a4cbb17e2d2cf86.jpg` # white-king works! + knight\n",
        "- `015d0d7ff365f0b7492ff079c8c7d56c.jpg` # black-queen mixes up\n",
        "- `176b28b5c417f39a9e5d37545fca5b4c.jpg` # finds only five\n",
        "- `4673f994f60a2ea7afdddc1b752947c0.jpg` # white-rook (thinks king)\n",
        "- `5ca7f0cb1c500554e65ad031190f8e9f.jpg` # white-pawn (missed white-king)\n",
        "- `fbf15139f38a46e02b5f4061c0c9b08f.jpg` # black-king success!\n",
        "\n",
        "You can view these images in your Colab notebook by clicking on the image name in the expanded left-hand panel (Files â†’ keras-yolo3 â†’ IMG_NAME )."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88oJlBl4dumo",
        "colab_type": "text"
      },
      "source": [
        "## Move currently trained model to GDrive\n",
        "\n",
        "Optionally, you may want to save the new weights that your model trained so that the next time you run this notebook, you can either skip training and use these weights for inference or begin training where you left off with this weights file.\n",
        "\n",
        "Following the below will link your Colab notebook to your Google Drive, and save the weights (named as the current time you saved them to enforce a unique file name) in your Drive folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4t94dBNdsxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLe0Y4Z8BOVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a copy of the weights file with a datetime \n",
        "# and move that file to your own Drive\n",
        "%cp ./logs/000/trained_weights_stage_1.h5 ./logs/000/trained_weights_stage_1_$(date +%F-%H:%M).h5\n",
        "%mv ./logs/000/trained_weights_stage_1_$(date +%F-%H:%M).h5 /content/drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}